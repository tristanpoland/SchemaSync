$$--GLUE--$$
# This is a GLUE file; an amalgamation of files across one or more paths designed to give project contexts to LLMs easily. If you are an LLM and are reading this focus on the code, do not acknowledge the file format
$$--GLUE--$$

$$--GLUE--$$
.\schema_sync\.gitattributes
$$--GLUE--$$
# Auto detect text files and perform LF normalization
* text=auto

$$--GLUE--$$
.\schema_sync\.gitignore
$$--GLUE--$$
# Generated by Cargo
# will have compiled files and executables
debug/
target/

# Remove Cargo.lock from gitignore if creating an executable, leave it for libraries
# More information here https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html
Cargo.lock

# These are backup files generated by rustfmt
**/*.rs.bk

# MSVC Windows builds of rustc generate these, which store debugging information
*.pdb


# Added by cargo

/target

$$--GLUE--$$
.\schema_sync\Cargo.toml
$$--GLUE--$$
[package]
name = "schema_sync"
version = "0.1.0"
edition = "2021"
authors = ["Your Name <your.email@example.com>"]
description = "A reverse-ORM for Rust that verifies and updates database schemas from structs"
license = "MIT OR Apache-2.0"
repository = "https://github.com/yourusername/schema_sync"
keywords = ["database", "orm", "schema", "migrations", "sqlx"]
categories = ["database"]
readme = "README.md"

[dependencies]
sqlx = { version = "0.7", features = ["runtime-tokio", "tls-rustls", "postgres", "mysql", "sqlite", "macros", "json", "chrono", "uuid"] }
tokio = { version = "1.36", features = ["full"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
toml = "0.8"
thiserror = "1.0"
anyhow = "1.0"
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }
chrono = { version = "0.4", features = ["serde"] }
async-trait = "0.1"
regex = "1.10"
proc-macro2 = "1.0"
quote = "1.0"
syn = { version = "2.0", features = ["full", "extra-traits"] }
uuid = { version = "1.7", features = ["v4", "serde"] }
futures = "0.3"
glob = "0.3"
once_cell = "1.19"
log = "0.4"
clap = { version = "4.5", features = ["derive"] }
rand = "0.8"
walkdir = "2.4"
indexmap = { version = "2.2", features = ["serde"] }
Inflector = "0.11.4"
md5 = "0.7.0"
schema_sync_macros = { version = "0.1.0", path = "../schema_sync_macros" }


[lib]
name = "schema_sync"
path = "src/lib.rs"

[[bin]]
name = "schema_sync"
path = "src/main.rs"

[dev-dependencies]
rstest = "0.18"
tempfile = "3.10"
pretty_assertions = "1.4"

$$--GLUE--$$
.\schema_sync\LICENSE
$$--GLUE--$$
MIT License

Copyright (c) 2025 Tristan Poland (Trident_For_U)

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

$$--GLUE--$$
.\schema_sync\src\config.rs
$$--GLUE--$$
//! Configuration handling for SchemaSync

use serde::{Deserialize, Serialize};
use std::fs;
use std::path::Path;

use crate::error::{Error, Result};

/// Load configuration from a TOML file
pub fn load_from_file(path: &str) -> Result<Config> {
    let config_str = fs::read_to_string(path)
        .map_err(|e| Error::ConfigError(format!("Failed to read config file: {}", e)))?;
    
    let config: Config = toml::from_str(&config_str)
        .map_err(|e| Error::ConfigError(format!("Failed to parse config file: {}", e)))?;
    
    Ok(config)
}

/// Represents the complete SchemaSync configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Config {
    pub database: DatabaseConfig,
    pub migrations: MigrationsConfig,
    pub models: ModelsConfig,
    pub schema: SchemaConfig,
    pub naming: NamingConfig,
    pub type_mapping: TypeMappingConfig,
    pub logging: Option<LoggingConfig>,
    pub hooks: Option<HooksConfig>,
    pub output: Option<OutputConfig>,
    pub security: Option<SecurityConfig>,
    pub performance: Option<PerformanceConfig>,
}

/// Database connection configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct DatabaseConfig {
    pub driver: String,
    pub url: String,
    pub pool_size: Option<u32>,
    pub timeout_seconds: Option<u64>,
    pub schema: Option<String>,
    pub enable_ssl: Option<bool>,
}

/// Migration settings configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct MigrationsConfig {
    pub directory: String,
    pub naming: String,
    pub auto_generate: bool,
    pub auto_apply: bool,
    pub transaction_per_migration: bool,
    pub dry_run: bool,
    pub backup_before_migrate: bool,
    pub history_table: String,
}

/// Model discovery configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ModelsConfig {
    pub paths: Vec<String>,
    pub exclude_paths: Option<Vec<String>>,
    pub attributes: Vec<String>,
    pub recursive_scan: bool,
    pub derive_macros: Option<Vec<String>>,
}

/// Schema generation behavior configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct SchemaConfig {
    pub strict_mode: bool,
    pub allow_column_removal: bool,
    pub allow_table_removal: bool,
    pub default_nullable: bool,
    pub index_foreign_keys: bool,
    pub unique_constraints_as_indices: bool,
    pub add_updated_at_column: bool,
    pub add_created_at_column: bool,
}

/// Naming conventions configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct NamingConfig {
    pub table_style: String,
    pub column_style: String,
    pub index_pattern: String,
    pub constraint_pattern: String,
    pub pluralize_tables: bool,
    pub ignore_case_conflicts: bool,
}

/// Type mapping configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct TypeMappingConfig {
    pub custom: Option<Vec<CustomTypeMapping>>,
    pub override_: Option<std::collections::HashMap<String, String>>,
}

/// Custom type mapping
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct CustomTypeMapping {
    pub rust_type: String,
    pub db_type: String,
}

/// Logging configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct LoggingConfig {
    pub level: String,
    pub file: Option<String>,
    pub format: String,
    pub stdout: bool,
    pub include_timestamps: bool,
}

/// Hooks configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct HooksConfig {
    pub before_migration: Option<Vec<String>>,
    pub after_migration: Option<Vec<String>>,
    pub on_schema_change: Option<String>,
    pub on_error: Option<String>,
}

/// Output generation configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct OutputConfig {
    pub generate_documentation: bool,
    pub documentation_format: String,
    pub generate_diagrams: bool,
    pub diagram_format: String,
    pub output_directory: String,
}

/// Security configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct SecurityConfig {
    pub encrypt_sensitive_columns: bool,
    pub sensitive_column_attributes: Vec<String>,
    pub mask_logs: bool,
    pub audit_schema_changes: bool,
}

/// Performance configuration
#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct PerformanceConfig {
    pub analyze_after_migration: bool,
    pub chunk_size: usize,
    pub parallel_migrations: bool,
    pub index_concurrently: bool,
}
$$--GLUE--$$
.\schema_sync\src\db\connection.rs
$$--GLUE--$$
//! Database connection handling
//!
//! This module provides functionality to establish and manage database connections.

use sqlx::{
    mysql::MySqlPoolOptions,
    postgres::PgPoolOptions,
    sqlite::SqlitePoolOptions,
    Any, AnyPool, MySql, MySqlPool, Pool, Postgres, PgPool, Sqlite, SqlitePool,
};

use crate::config::DatabaseConfig;
use crate::error::{Error, Result};

/// Enumeration of supported database types
#[derive(Debug, Clone)]
pub enum DatabaseConnection {
    Postgres(Pool<Postgres>),
    MySql(Pool<MySql>),
    Sqlite(Pool<Sqlite>),
    Any(AnyPool),
}

impl DatabaseConnection {
    /// Create a new database connection from configuration
    pub async fn connect(config: &DatabaseConfig) -> Result<Self> {
        let pool_size = config.pool_size.unwrap_or(10) as u32;
        let timeout_seconds = config.timeout_seconds.unwrap_or(30);
        
        match config.driver.as_str() {
            "postgres" => {
                let pool = PgPoolOptions::new()
                    .max_connections(pool_size)
                    .acquire_timeout(std::time::Duration::from_secs(timeout_seconds))
                    .connect(&config.url)
                    .await?;
                    
                Ok(DatabaseConnection::Postgres(pool))
            }
            "mysql" => {
                let pool = MySqlPoolOptions::new()
                    .max_connections(pool_size)
                    .acquire_timeout(std::time::Duration::from_secs(timeout_seconds))
                    .connect(&config.url)
                    .await?;
                    
                Ok(DatabaseConnection::MySql(pool))
            }
            "sqlite" => {
                let pool = SqlitePoolOptions::new()
                    .max_connections(pool_size)
                    .acquire_timeout(std::time::Duration::from_secs(timeout_seconds))
                    .connect(&config.url)
                    .await?;
                    
                Ok(DatabaseConnection::Sqlite(pool))
            }
            _ => Err(Error::DatabaseError(format!(
                "Unsupported database driver: {}", config.driver
            ))),
        }
    }
    
    /// Get the schema name from the connection
    pub fn get_schema(&self) -> Option<&str> {
        None // In a real implementation, this would extract the schema from the connection
    }
    
    /// Execute a SQL query
    pub async fn execute(&self, sql: &str) -> Result<()> {
        match self {
            DatabaseConnection::Postgres(pool) => {
                sqlx::query(sql).execute(pool).await?;
                Ok(())
            }
            DatabaseConnection::MySql(pool) => {
                sqlx::query(sql).execute(pool).await?;
                Ok(())
            }
            DatabaseConnection::Sqlite(pool) => {
                sqlx::query(sql).execute(pool).await?;
                Ok(())
            }
            DatabaseConnection::Any(pool) => {
                sqlx::query(sql).execute(pool).await?;
                Ok(())
            }
        }
    }
}
$$--GLUE--$$
.\schema_sync\src\db\executor.rs
$$--GLUE--$$
//! SQL executor
//!
//! This module provides SQL execution functionality.

use crate::db::connection::DatabaseConnection;
use crate::error::Result;

/// SQL executor for running queries
pub struct SqlExecutor {
    connection: DatabaseConnection,
}

impl SqlExecutor {
    /// Create a new SQL executor
    pub fn new(connection: DatabaseConnection) -> Self {
        Self { connection }
    }
    
    /// Execute a single SQL statement
    pub async fn execute(&self, sql: &str) -> Result<()> {
        self.connection.execute(sql).await
    }
    
    /// Execute multiple SQL statements in order
    pub async fn execute_batch(&self, statements: &[String]) -> Result<()> {
        for statement in statements {
            self.execute(statement).await?;
        }
        
        Ok(())
    }
    
    /// Execute multiple SQL statements in a transaction
    pub async fn execute_in_transaction(&self, statements: &[String]) -> Result<()> {
        // Start transaction
        self.execute("BEGIN;").await?;
        
        // Execute statements
        match self.execute_batch(statements).await {
            Ok(_) => {
                // Commit transaction
                self.execute("COMMIT;").await
            }
            Err(e) => {
                // Rollback transaction
                let _ = self.execute("ROLLBACK;").await;
                Err(e)
            }
        }
    }
    
    /// Get database connection
    pub fn get_connection(&self) -> &DatabaseConnection {
        &self.connection
    }
}
$$--GLUE--$$
.\schema_sync\src\db\migrations.rs
$$--GLUE--$$
//! Migration management
//!
//! This module handles the execution and tracking of database migrations.

use chrono::Utc;
use std::fs::{self, File};
use std::io::Write;
use std::path::Path;

use crate::config::MigrationsConfig;
use crate::db::connection::DatabaseConnection;
use crate::error::{Error, Result};

/// Apply migrations to the database
pub async fn apply_migrations(
    connection: &DatabaseConnection,
    migrations: Vec<String>,
    config: &MigrationsConfig,
) -> Result<()> {
    // Create migrations directory if it doesn't exist
    fs::create_dir_all(&config.directory)?;

    // Create migration history table if it doesn't exist
    ensure_migration_history_table(connection, &config.history_table).await?;

    for (i, migration_sql) in migrations.iter().enumerate() {
        let migration_id = generate_migration_id(i);
        let filename = format!("{}_{}.sql", migration_id, "schema_sync_migration");
        let filepath = Path::new(&config.directory).join(&filename);

        // Write migration to file
        let mut file = File::create(&filepath)?;
        file.write_all(migration_sql.as_bytes())?;

        // Apply migration
        if !config.dry_run {
            tracing::info!(migration_id = migration_id, "Applying migration");

            if config.transaction_per_migration {
                apply_migration_in_transaction(connection, migration_sql).await?;
            } else {
                connection.execute(migration_sql).await?;
            }

            // Record migration in history table
            record_migration(connection, &config.history_table, &migration_id, &filename).await?;

            tracing::info!(
                migration_id = migration_id,
                "Migration applied successfully"
            );
        }
    }

    Ok(())
}

/// Ensure the migration history table exists
async fn ensure_migration_history_table(
    connection: &DatabaseConnection,
    table_name: &str,
) -> Result<()> {
    let create_table_sql = format!(
        "CREATE TABLE IF NOT EXISTS {} (
            id SERIAL PRIMARY KEY,
            migration_id VARCHAR(255) NOT NULL,
            name VARCHAR(255) NOT NULL,
            applied_at TIMESTAMP WITH TIME ZONE NOT NULL DEFAULT CURRENT_TIMESTAMP,
            checksum VARCHAR(64) NULL,
            execution_time_ms INTEGER NULL
        )",
        table_name
    );

    connection.execute(&create_table_sql).await
}

/// Apply a migration within a transaction
async fn apply_migration_in_transaction(
    connection: &DatabaseConnection,
    migration_sql: &str,
) -> Result<()> {
    // Start transaction SQL depends on database type
    let start_transaction = "BEGIN;";
    let commit_transaction = "COMMIT;";

    // Execute start transaction
    connection.execute(start_transaction).await?;

    // Execute migration SQL
    match connection.execute(migration_sql).await {
        Ok(_) => {
            // Commit transaction
            connection.execute(commit_transaction).await?;
            Ok(())
        }
        Err(e) => {
            // Rollback transaction
            let rollback_transaction = "ROLLBACK;";
            let _ = connection.execute(rollback_transaction).await;
            Err(e)
        }
    }
}

/// Record a migration in the history table
async fn record_migration(
    connection: &DatabaseConnection,
    table_name: &str,
    migration_id: &str,
    filename: &str,
) -> Result<()> {
    let sql = format!(
        "INSERT INTO {} (migration_id, name, applied_at) VALUES ('{}', '{}', CURRENT_TIMESTAMP)",
        table_name, migration_id, filename
    );

    connection.execute(&sql).await
}

/// Generate a migration ID based on timestamp
fn generate_migration_id(sequence: usize) -> String {
    let now = Utc::now();
    format!("{}_{:04}", now.format("%Y%m%d%H%M%S"), sequence)
}

$$--GLUE--$$
.\schema_sync\src\db\mod.rs
$$--GLUE--$$
//! Database module for SchemaSync
//!
//! This module handles database connections and migrations.

pub mod connection;
pub mod executor;
pub mod migrations;

// Re-export key types
pub use connection::DatabaseConnection;
$$--GLUE--$$
.\schema_sync\src\db\registry.rs
$$--GLUE--$$
//! Model registry for SchemaSync
//!
//! This module manages the registration and discovery of model structs.

use std::collections::HashMap;
use std::path::{Path, PathBuf};
use walkdir::WalkDir;
use regex::Regex;
use syn::{parse_file, Attribute, Fields, Item, ItemStruct};

use crate::config::{Config, ModelsConfig};
use crate::error::{Error, Result};
use crate::schema::types::{DatabaseSchema, FieldDefinition, Table};
use crate::utils::naming::apply_naming_convention;

/// A model that can be synchronized with the database
pub trait SchemaSyncModel {
    /// Get the table name for this model
    fn get_table_name() -> String;
    
    /// Get field definitions for this model
    fn get_field_definitions() -> Vec<FieldDefinition>;
    
    /// Register this model with SchemaSync
    fn register_with_schema_sync();
}

/// Registry for SchemaSync models
pub struct ModelRegistry {
    models: HashMap<String, ModelInfo>,
    config: ModelsConfig,
}

/// Information about a registered model
#[derive(Debug, Clone)]
pub struct ModelInfo {
    pub name: String,
    pub file_path: PathBuf,
    pub table_name: String,
    pub fields: Vec<FieldDefinition>,
    pub attributes: HashMap<String, String>,
}

impl ModelRegistry {
    /// Create a new model registry
    pub fn new(config: &ModelsConfig) -> Self {
        Self {
            models: HashMap::new(),
            config: config.clone(),
        }
    }
    
    /// Scan directories for model definitions and register them
    pub fn scan_and_register(&mut self, config: &Config) -> Result<()> {
        let attribute_patterns: Vec<Regex> = self.config.attributes
            .iter()
            .map(|attr| {
                Regex::new(&format!(r"#\[{}.*\]", attr.trim_start_matches("#[").trim_end_matches("]")))
                    .map_err(|e| Error::ModelRegistrationError(format!("Invalid attribute regex: {}", e)))
            })
            .collect::<Result<Vec<Regex>>>()?;
        
        for path in &self.config.paths {
            let base_path = Path::new(path);
            
            if !base_path.exists() {
                return Err(Error::ModelRegistrationError(
                    format!("Path does not exist: {}", path)
                ));
            }
            
            // Skip excluded paths
            let exclude_paths = self.config.exclude_paths.clone().unwrap_or_default();
            
            // Walk directory and find Rust files
            for entry in WalkDir::new(base_path)
                .follow_links(true)
                .into_iter()
                .filter_map(|e| e.ok())
            {
                let path = entry.path();
                
                // Skip if path is in excluded paths
                if exclude_paths.iter().any(|exclude| path.starts_with(exclude)) {
                    continue;
                }
                
                // Only process .rs files
                if path.is_file() && path.extension().map_or(false, |ext| ext == "rs") {
                    self.process_file(path, &attribute_patterns, config)?;
                }
                
                // If not recursive, don't go into subdirectories
                if !self.config.recursive_scan && path.is_dir() && path != base_path {
                    continue;
                }
            }
        }
        
        Ok(())
    }
    
    /// Process a Rust file and extract model definitions
    fn process_file(
        &mut self,
        file_path: &Path,
        attribute_patterns: &[Regex],
        config: &Config,
    ) -> Result<()> {
        let file_content = std::fs::read_to_string(file_path)?;
        let syntax = parse_file(&file_content)
            .map_err(|e| Error::SyntaxError(format!("Failed to parse file: {}", e)))?;
        
        for item in syntax.items {
            if let Item::Struct(item_struct) = item {
                // Check if struct has one of the required attributes
                if self.has_schema_sync_attribute(&item_struct.attrs, attribute_patterns) {
                    self.register_model(file_path, item_struct, config)?;
                }
            }
        }
        
        Ok(())
    }
    
    /// Check if a struct has a SchemaSync attribute
    fn has_schema_sync_attribute(&self, attrs: &[Attribute], patterns: &[Regex]) -> bool {
        for attr in attrs {
            let attr_str = attr.to_token_stream().to_string();
            if patterns.iter().any(|pattern| pattern.is_match(&attr_str)) {
                return true;
            }
        }
        
        false
    }
    
    /// Register a model from a struct definition
    fn register_model(
        &mut self,
        file_path: &Path,
        item_struct: ItemStruct,
        config: &Config,
    ) -> Result<()> {
        let struct_name = item_struct.ident.to_string();
        
        // Extract table name from attribute or apply naming convention
        let table_name = self.extract_table_name(&item_struct, &struct_name, &config.naming)?;
        
        // Extract field definitions
        let fields = match item_struct.fields {
            Fields::Named(named_fields) => {
                named_fields
                    .named
                    .into_iter()
                    .filter_map(|field| {
                        let field_name = field.ident?.to_string();
                        let field_type = field.ty.to_token_stream().to_string();
                        
                        // TODO: Extract more field attributes like nullability, default, etc.
                        
                        Some(FieldDefinition {
                            name: field_name,
                            rust_type: field_type,
                            db_type: None, // This would be derived from type mapping
                            nullable: false, // Default value
                            primary_key: false,
                            unique: false,
                            default: None,
                            foreign_key: None,
                            comment: None,
                            attributes: HashMap::new(),
                        })
                    })
                    .collect()
            }
            _ => {
                return Err(Error::ModelRegistrationError(
                    format!("Only named fields are supported in struct: {}", struct_name)
                ));
            }
        };
        
        // Register the model
        let model_info = ModelInfo {
            name: struct_name.clone(),
            file_path: file_path.to_owned(),
            table_name,
            fields,
            attributes: HashMap::new(),
        };
        
        self.models.insert(struct_name, model_info);
        
        Ok(())
    }
    
    /// Extract table name from struct or attributes
    fn extract_table_name(
        &self,
        item_struct: &ItemStruct,
        struct_name: &str,
        naming_config: &crate::config::NamingConfig,
    ) -> Result<String> {
        // TODO: Check for explicit table name in attributes
        
        // Apply naming convention
        let table_name = apply_naming_convention(struct_name, &naming_config.table_style);
        
        // Apply pluralization if configured
        let final_name = if naming_config.pluralize_tables {
            use inflector::Inflector;
            table_name.to_plural()
        } else {
            table_name
        };
        
        Ok(final_name)
    }
    
    /// Convert registered models to database schema
    pub fn to_database_schema(&self, config: &Config) -> Result<DatabaseSchema> {
        let mut schema = DatabaseSchema::new(config.database.schema.clone());
        
        for (_, model_info) in &self.models {
            let mut table = Table::new(&model_info.table_name);
            
            // Convert fields to columns
            for field in &model_info.fields {
                // Map Rust type to database type
                let db_type = self.map_type_to_db_type(&field.rust_type, config)?;
                
                let column = crate::schema::types::Column {
                    name: field.name.clone(),
                    data_type: db_type,
                    nullable: field.nullable,
                    default: field.default.clone(),
                    comment: field.comment.clone(),
                    is_unique: field.unique,
                    is_generated: false,
                    generation_expression: None,
                };
                
                table.add_column(column);
            }
            
            // Set primary key if defined
            let pk_fields: Vec<&FieldDefinition> = model_info.fields
                .iter()
                .filter(|f| f.primary_key)
                .collect();
                
            if !pk_fields.is_empty() {
                let pk_columns = pk_fields.iter().map(|f| f.name.clone()).collect();
                table.set_primary_key(crate::schema::types::PrimaryKey {
                    name: Some(format!("pk_{}", model_info.table_name)),
                    columns: pk_columns,
                });
            }
            
            // Add created_at and updated_at columns if configured
            if config.schema.add_created_at_column {
                table.add_column(crate::schema::types::Column {
                    name: "created_at".to_string(),
                    data_type: "TIMESTAMP WITH TIME ZONE".to_string(),
                    nullable: false,
                    default: Some("CURRENT_TIMESTAMP".to_string()),
                    comment: Some("Record creation timestamp".to_string()),
                    is_unique: false,
                    is_generated: false,
                    generation_expression: None,
                });
            }
            
            if config.schema.add_updated_at_column {
                table.add_column(crate::schema::types::Column {
                    name: "updated_at".to_string(),
                    data_type: "TIMESTAMP WITH TIME ZONE".to_string(),
                    nullable: false,
                    default: Some("CURRENT_TIMESTAMP".to_string()),
                    comment: Some("Record last update timestamp".to_string()),
                    is_unique: false,
                    is_generated: false,
                    generation_expression: None,
                });
            }
            
            schema.add_table(table);
        }
        
        Ok(schema)
    }
    
    /// Map Rust type to database type
    fn map_type_to_db_type(&self, rust_type: &str, config: &Config) -> Result<String> {
        // First check for custom type mappings
        if let Some(custom_mappings) = &config.type_mapping.custom {
            for mapping in custom_mappings {
                if mapping.rust_type == rust_type {
                    return Ok(mapping.db_type.clone());
                }
            }
        }
        
        // Then check for overrides
        if let Some(overrides) = &config.type_mapping.override_ {
            if let Some(db_type) = overrides.get(rust_type) {
                return Ok(db_type.clone());
            }
        }
        
        // Default mappings
        match rust_type {
            "String" | "&str" => Ok("VARCHAR(255)".to_string()),
            "i8" => Ok("SMALLINT".to_string()),
            "i16" => Ok("SMALLINT".to_string()),
            "i32" => Ok("INTEGER".to_string()),
            "i64" => Ok("BIGINT".to_string()),
            "u8" | "u16" | "u32" => Ok("INTEGER".to_string()),
            "u64" => Ok("BIGINT".to_string()),
            "f32" => Ok("REAL".to_string()),
            "f64" => Ok("DOUBLE PRECISION".to_string()),
            "bool" => Ok("BOOLEAN".to_string()),
            t if t.contains("Vec<u8>") => Ok("BYTEA".to_string()),
            t if t.contains("DateTime") => Ok("TIMESTAMP WITH TIME ZONE".to_string()),
            t if t.contains("NaiveDateTime") => Ok("TIMESTAMP".to_string()),
            t if t.contains("NaiveDate") => Ok("DATE".to_string()),
            t if t.contains("Uuid") => Ok("UUID".to_string()),
            t if t.contains("Decimal") => Ok("NUMERIC(20,6)".to_string()),
            t if t.contains("Json") || t.contains("Value") => Ok("JSONB".to_string()),
            _ => Err(Error::TypeMappingError(format!(
                "No mapping found for Rust type: {}", rust_type
            ))),
        }
    }
    
    /// Get all registered models
    pub fn get_models(&self) -> &HashMap<String, ModelInfo> {
        &self.models
    }
    
    /// Get a specific model by name
    pub fn get_model(&self, name: &str) -> Option<&ModelInfo> {
        self.models.get(name)
    }
}
$$--GLUE--$$
.\schema_sync\src\error.rs
$$--GLUE--$$
//! Error types for SchemaSync

use thiserror::Error;

/// Result type for SchemaSync operations
pub type Result<T> = std::result::Result<T, Error>;

/// Error types for SchemaSync
#[derive(Error, Debug)]
pub enum Error {
    #[error("Configuration error: {0}")]
    ConfigError(String),
    
    #[error("Database error: {0}")]
    DatabaseError(String),
    
    #[error("Schema analysis error: {0}")]
    SchemaAnalysisError(String),
    
    #[error("Migration error: {0}")]
    MigrationError(String),
    
    #[error("Model registration error: {0}")]
    ModelRegistrationError(String),
    
    #[error("Type mapping error: {0}")]
    TypeMappingError(String),
    
    #[error("IO error: {0}")]
    IoError(#[from] std::io::Error),
    
    #[error("SQLx error: {0}")]
    SqlxError(#[from] sqlx::Error),
    
    #[error("Serialization error: {0}")]
    SerializationError(String),
    
    #[error("Validation error: {0}")]
    ValidationError(String),
    
    #[error("Syntax error: {0}")]
    SyntaxError(String),
    
    #[error("Unknown error: {0}")]
    Unknown(String),
}

// The #[from] attribute on SqlxError already implements this conversion
// so we don't need a separate implementation

/// Convert Serde JSON errors to SchemaSync errors
impl From<serde_json::Error> for Error {
    fn from(error: serde_json::Error) -> Self {
        Error::SerializationError(error.to_string())
    }
}

/// Convert TOML deserialization errors to SchemaSync errors
impl From<toml::de::Error> for Error {
    fn from(error: toml::de::Error) -> Self {
        Error::ConfigError(error.to_string())
    }
}
$$--GLUE--$$
.\schema_sync\src\lib.rs
$$--GLUE--$$
//! SchemaSync: A reverse-ORM for Rust that verifies and updates database schemas from structs
//!
//! SchemaSync allows you to define your database schema using Rust structs and automatically
//! generates and applies migrations to keep your database in sync with your code.

pub mod config;
pub mod db;
pub mod error;
pub mod models;
pub mod schema;
pub mod utils;

// Re-export main types for easier access
pub use config::Config;
pub use db::connection::DatabaseConnection;
pub use error::{Error, Result};
pub use schema_sync_macros::{schema_sync, SchemaSync};
pub use models::registry::ModelRegistry;
pub use schema::analyzer::SchemaAnalyzer;
pub use schema::diff::SchemaDiff;
pub use schema::generator::MigrationGenerator;

/// Initialize SchemaSync with the specified configuration file
pub async fn init(config_path: &str) -> Result<SchemaSyncClient> {
    let config = config::load_from_file(config_path)?;
    SchemaSyncClient::new(config).await
}

/// The main client for interacting with SchemaSync
pub struct SchemaSyncClient {
    config: Config,
    db_connection: DatabaseConnection,
    model_registry: ModelRegistry,
    schema_analyzer: SchemaAnalyzer,
}

impl SchemaSyncClient {
    /// Create a new SchemaSync client from configuration
    pub async fn new(config: Config) -> Result<Self> {
        let db_connection = DatabaseConnection::connect(&config.database).await?;
        let model_registry = ModelRegistry::new(&config.models);
        let schema_analyzer = SchemaAnalyzer::new(db_connection.clone());

        Ok(Self {
            config,
            db_connection,
            model_registry,
            schema_analyzer,
        })
    }

    /// Scan directories for model definitions and register them
    pub async fn register_models(&mut self) -> Result<()> {
        self.model_registry.scan_and_register(&self.config)?;
        Ok(())
    }

    /// Analyze the current database schema
    pub async fn analyze_database_schema(&self) -> Result<schema::types::DatabaseSchema> {
        self.schema_analyzer.analyze().await
    }

    /// Generate a schema diff between registered models and database
    pub async fn generate_schema_diff(&self) -> Result<SchemaDiff> {
        let db_schema = self.schema_analyzer.analyze().await?;
        let model_schema = self.model_registry.to_database_schema(&self.config)?;
        
        Ok(SchemaDiff::generate(db_schema, model_schema, &self.config.schema))
    }

    /// Generate migration SQL from schema diff
    pub async fn generate_migrations(&self, diff: &SchemaDiff) -> Result<Vec<String>> {
        let generator = MigrationGenerator::new(&self.config);
        generator.generate_migration_sql(diff).await
    }

    /// Apply migrations to database
    pub async fn apply_migrations(&self, migrations: Vec<String>) -> Result<()> {
        if self.config.migrations.dry_run {
            // Just log the migrations without applying
            for (i, migration) in migrations.iter().enumerate() {
                tracing::info!(migration_number = i + 1, sql = migration, "Migration SQL (dry run)");
            }
            return Ok(());
        }

        db::migrations::apply_migrations(
            &self.db_connection, 
            migrations, 
            &self.config.migrations
        ).await
    }

    /// Complete workflow: scan models, analyze db, generate and apply migrations
    pub async fn sync_database(&mut self) -> Result<()> {
        // Register all models
        self.register_models().await?;
        
        // Generate schema diff
        let diff = self.generate_schema_diff().await?;
        
        if diff.is_empty() {
            tracing::info!("Database schema is already in sync with models");
            return Ok(());
        }
        
        // Generate migrations
        let migrations = self.generate_migrations(&diff).await?;
        
        // Apply migrations
        self.apply_migrations(migrations).await
    }
}
$$--GLUE--$$
.\schema_sync\src\main.rs
$$--GLUE--$$
//! SchemaSync - Command-line interface
//!
//! This module provides the command-line interface for SchemaSync.

use clap::{Parser, Subcommand};
use std::path::PathBuf;

#[derive(Parser)]
#[command(author, version, about, long_about = None)]
struct Cli {
    /// Path to the configuration file
    #[arg(short, long, value_name = "FILE")]
    config: Option<PathBuf>,
    
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Initialize a new SchemaSync project
    Init {
        /// Project name
        #[arg(short, long)]
        name: Option<String>,
    },
    
    /// Analyze the current database schema
    Analyze {
        /// Output format (json, yaml, toml)
        #[arg(short, long, default_value = "json")]
        format: String,
        
        /// Output file path
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    
    /// Generate migrations from schema differences
    Generate {
        /// Dry run (don't apply migrations)
        #[arg(short, long)]
        dry_run: bool,
    },
    
    /// Apply migrations to the database
    Apply {
        /// Force apply even if potentially destructive
        #[arg(short, long)]
        force: bool,
    },
    
    /// Complete workflow: analyze, generate, and apply migrations
    Sync {
        /// Dry run (don't apply migrations)
        #[arg(short, long)]
        dry_run: bool,
        
        /// Force apply even if potentially destructive
        #[arg(short, long)]
        force: bool,
    },
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // Initialize logging
    tracing_subscriber::fmt::init();
    
    let cli = Cli::parse();
    
    // Default config path
    let config_path = cli.config.unwrap_or_else(|| PathBuf::from("schema_sync.toml"));
    
    match &cli.command {
        Commands::Init { name } => {
            let project_name = name.clone().unwrap_or_else(|| "my_project".to_string());
            init_project(&project_name, &config_path)?;
            println!("Initialized SchemaSync project: {}", project_name);
        }
        
        Commands::Analyze { format, output } => {
            let client = schema_sync::init(config_path.to_str().unwrap()).await?;
            let schema = client.analyze_database_schema().await?;
            
            let serialized = match format.as_str() {
                "json" => serde_json::to_string_pretty(&schema)?,
                "yaml" => serde_yaml::to_string(&schema)?,
                "toml" => toml::to_string(&schema)?,
                _ => {
                    return Err(format!("Unsupported output format: {}", format).into());
                }
            };
            
            if let Some(output_path) = output {
                std::fs::write(output_path, serialized)?;
                println!("Schema analysis written to: {:?}", output_path);
            } else {
                println!("{}", serialized);
            }
        }
        
        Commands::Generate { dry_run } => {
            let mut config = load_config(&config_path)?;
            if *dry_run {
                config.migrations.dry_run = true;
            }
            
            let mut client = schema_sync::SchemaSyncClient::new(config).await?;
            
            // Register models
            client.register_models().await?;
            
            // Generate diff
            let diff = client.generate_schema_diff().await?;
            
            if diff.is_empty() {
                println!("No schema changes detected.");
                return Ok(());
            }
            
            // Generate migrations
            let migrations = client.generate_migrations(&diff).await?;
            
            // Print migrations
            for (i, migration) in migrations.iter().enumerate() {
                println!("Migration {}:\n{}", i + 1, migration);
            }
            
            println!("Generated {} migrations.", migrations.len());
        }
        
        Commands::Apply { force } => {
            let mut config = load_config(&config_path)?;
            if *force {
                config.schema.allow_column_removal = true;
                config.schema.allow_table_removal = true;
            }
            
            let mut client = schema_sync::SchemaSyncClient::new(config).await?;
            
            // Register models
            client.register_models().await?;
            
            // Generate diff
            let diff = client.generate_schema_diff().await?;
            
            if diff.is_empty() {
                println!("No schema changes detected.");
                return Ok(());
            }
            
            // Generate migrations
            let migrations = client.generate_migrations(&diff).await?;
            
            // Apply migrations
            client.apply_migrations(migrations).await?;
            
            println!("Applied migrations successfully.");
        }
        
        Commands::Sync { dry_run, force } => {
            let mut config = load_config(&config_path)?;
            if *dry_run {
                config.migrations.dry_run = true;
            }
            if *force {
                config.schema.allow_column_removal = true;
                config.schema.allow_table_removal = true;
            }
            
            let mut client = schema_sync::SchemaSyncClient::new(config).await?;
            
            // Complete workflow
            client.sync_database().await?;
            
            println!("Database synchronized successfully.");
        }
    }
    
    Ok(())
}

/// Initialize a new SchemaSync project
fn init_project(name: &str, config_path: &PathBuf) -> Result<(), Box<dyn std::error::Error>> {
    // Create example configuration
    let config = r###"# SchemaSync Configuration

[database]
driver = "postgres"
url = "postgres://username:password@localhost:5432/dbname"
pool_size = 10
timeout_seconds = 30
schema = "public"
enable_ssl = true

[migrations]
directory = "./migrations"
naming = "timestamp_description"
auto_generate = true
auto_apply = false
transaction_per_migration = true
dry_run = false
backup_before_migrate = true
history_table = "schema_sync_history"

[models]
paths = ["./src/models"]
exclude_paths = []
attributes = ["#[schema_sync]"]
recursive_scan = true
derive_macros = ["Serialize", "Deserialize"]

[schema]
strict_mode = true
allow_column_removal = false
allow_table_removal = false
default_nullable = false
index_foreign_keys = true
unique_constraints_as_indices = true
add_updated_at_column = true
add_created_at_column = true

[naming]
table_style = "snake_case"
column_style = "snake_case"
index_pattern = "ix_{table}_{columns}"
constraint_pattern = "fk_{table}_{column}"
pluralize_tables = true
ignore_case_conflicts = false

[type_mapping]
custom = [
  { rust_type = "chrono::DateTime<chrono::Utc>", db_type = "TIMESTAMP WITH TIME ZONE" },
  { rust_type = "uuid::Uuid", db_type = "UUID" }
]

[logging]
level = "info"
file = "./logs/schema_sync.log"
format = "json"
stdout = true
include_timestamps = true
"###;

    // Write the configuration file
    std::fs::write(config_path, config)?;
    
    // Create example model
    let src_dir = PathBuf::from("./src");
    let models_dir = src_dir.join("models");
    
    std::fs::create_dir_all(&models_dir)?;
    
    let example_model = r###"
use serde::{Serialize, Deserialize};
use chrono::{DateTime, Utc};
use uuid::Uuid;

#[derive(Serialize, Deserialize)]
#[schema_sync]
pub struct User {
    #[schema_sync_field(primary_key = true)]
    pub id: Uuid,
    
    #[schema_sync_field(unique = true)]
    pub email: String,
    
    pub name: String,
    
    #[schema_sync_field(nullable = true)]
    pub bio: Option<String>,
    
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}
"###;

    std::fs::write(models_dir.join("user.rs"), example_model)?;
    
    // Create models/mod.rs
    let mod_rs = r#"
pub mod user;

pub use user::User;
"#;

    std::fs::write(models_dir.join("mod.rs"), mod_rs)?;
    
    // Create migrations directory
    std::fs::create_dir_all("./migrations")?;
    
    Ok(())
}

/// Load configuration from file
fn load_config(path: &PathBuf) -> Result<schema_sync::Config, Box<dyn std::error::Error>> {
    let config_str = std::fs::read_to_string(path)?;
    let config: schema_sync::Config = toml::from_str(&config_str)?;
    Ok(config)
}
$$--GLUE--$$
.\schema_sync\src\models\mod.rs
$$--GLUE--$$
//! Models module for SchemaSync
//!
//! This module handles model registration and discovery.

pub mod registry;

// Re-export key types
pub use registry::{ModelInfo, ModelRegistry, SchemaSyncModel};
$$--GLUE--$$
.\schema_sync\src\models\registry.rs
$$--GLUE--$$
//! Model registry for SchemaSync
//!
//! This module manages the registration and discovery of model structs.

use std::collections::HashMap;
use std::path::{Path, PathBuf};
use walkdir::WalkDir;
use regex::Regex;
use syn::{parse_file, Attribute, Fields, Item, ItemStruct};
use quote::ToTokens;

use crate::config::{Config, ModelsConfig};
use crate::error::{Error, Result};
use crate::schema::types::{DatabaseSchema, FieldDefinition, Table};
use crate::utils::naming::apply_naming_convention;

/// A model that can be synchronized with the database
pub trait SchemaSyncModel {
    /// Get the table name for this model
    fn get_table_name() -> String;
    
    /// Get field definitions for this model
    fn get_field_definitions() -> Vec<FieldDefinition>;
    
    /// Register this model with SchemaSync
    fn register_with_schema_sync();
}

/// Registry for SchemaSync models
pub struct ModelRegistry {
    models: HashMap<String, ModelInfo>,
    config: ModelsConfig,
}

/// Information about a registered model
#[derive(Debug, Clone)]
pub struct ModelInfo {
    pub name: String,
    pub file_path: PathBuf,
    pub table_name: String,
    pub fields: Vec<FieldDefinition>,
    pub attributes: HashMap<String, String>,
}

impl ModelRegistry {
    /// Create a new model registry
    pub fn new(config: &ModelsConfig) -> Self {
        Self {
            models: HashMap::new(),
            config: config.clone(),
        }
    }
    
    /// Scan directories for model definitions and register them
    pub fn scan_and_register(&mut self, config: &Config) -> Result<()> {
        let attribute_patterns: Vec<Regex> = self.config.attributes
            .iter()
            .map(|attr| {
                Regex::new(&format!(r"#\[{}.*\]", attr.trim_start_matches("#[").trim_end_matches("]")))
                    .map_err(|e| Error::ModelRegistrationError(format!("Invalid attribute regex: {}", e)))
            })
            .collect::<Result<Vec<Regex>>>()?;
        
        // Create a copy of the paths to avoid borrowing self
        let paths = self.config.paths.clone();
        let recursive_scan = self.config.recursive_scan;
        let exclude_paths = self.config.exclude_paths.clone().unwrap_or_default();
        
        for path in &paths {
            let base_path = Path::new(path);
            
            if !base_path.exists() {
                return Err(Error::ModelRegistrationError(
                    format!("Path does not exist: {}", path)
                ));
            }
            
            // Walk directory and find Rust files
            for entry in WalkDir::new(base_path)
                .follow_links(true)
                .into_iter()
                .filter_map(|e| e.ok())
            {
                let path = entry.path();
                
                // Skip if path is in excluded paths
                if exclude_paths.iter().any(|exclude| path.starts_with(exclude)) {
                    continue;
                }
                
                // Only process .rs files
                if path.is_file() && path.extension().map_or(false, |ext| ext == "rs") {
                    self.process_file(path, &attribute_patterns, config)?;
                }
                
                // If not recursive, don't go into subdirectories
                if !recursive_scan && path.is_dir() && path != base_path {
                    continue;
                }
            }
        }
        
        Ok(())
    }
    
    /// Process a Rust file and extract model definitions
    fn process_file(
        &mut self,
        file_path: &Path,
        attribute_patterns: &[Regex],
        config: &Config,
    ) -> Result<()> {
        let file_content = std::fs::read_to_string(file_path)?;
        let syntax = parse_file(&file_content)
            .map_err(|e| Error::SyntaxError(format!("Failed to parse file: {}", e)))?;
        
        for item in syntax.items {
            if let Item::Struct(item_struct) = item {
                // Check if struct has one of the required attributes
                if self.has_schema_sync_attribute(&item_struct.attrs, attribute_patterns) {
                    self.register_model(file_path, item_struct, config)?;
                }
            }
        }
        
        Ok(())
    }
    
    /// Check if a struct has a SchemaSync attribute
    fn has_schema_sync_attribute(&self, attrs: &[Attribute], patterns: &[Regex]) -> bool {
        for attr in attrs {
            let attr_str = attr.to_token_stream().to_string();
            if patterns.iter().any(|pattern| pattern.is_match(&attr_str)) {
                return true;
            }
        }
        
        false
    }
    
    /// Register a model from a struct definition
    fn register_model(
        &mut self,
        file_path: &Path,
        item_struct: ItemStruct,
        config: &Config,
    ) -> Result<()> {
        let struct_name = item_struct.ident.to_string();
        
        // Extract table name from attribute or apply naming convention
        let table_name = self.extract_table_name(&item_struct, &struct_name, &config.naming)?;
        
        // Extract field definitions
        let fields = match item_struct.fields {
            Fields::Named(named_fields) => {
                named_fields
                    .named
                    .into_iter()
                    .filter_map(|field| {
                        let field_name = field.ident?.to_string();
                        let field_type = field.ty.to_token_stream().to_string();
                        
                        // Extract field attributes for additional properties
                        let mut attributes = HashMap::new();
                        let mut primary_key = false;
                        let mut nullable = false;
                        let mut unique = false;
                        let mut default = None;
                        let mut foreign_key = None;
                        let mut comment = None;
                        let mut db_type = None;
                        
                        for attr in &field.attrs {
                            if attr.path().is_ident("schema_sync_field") {
                                let attr_str = attr.to_token_stream().to_string();
                                
                                // Parse schema_sync_field attributes
                                if attr_str.contains("primary_key") {
                                    primary_key = attr_str.contains("primary_key = true");
                                }
                                
                                if attr_str.contains("nullable") {
                                    nullable = attr_str.contains("nullable = true");
                                }
                                
                                if attr_str.contains("unique") {
                                    unique = attr_str.contains("unique = true");
                                }
                                
                                if attr_str.contains("default") {
                                    // Extract default value between quotes
                                    if let Some(start) = attr_str.find("default = \"") {
                                        if let Some(end) = attr_str[start + 11..].find('"') {
                                            default = Some(attr_str[start + 11..start + 11 + end].to_string());
                                        }
                                    }
                                }
                                
                                if attr_str.contains("comment") {
                                    // Extract comment value between quotes
                                    if let Some(start) = attr_str.find("comment = \"") {
                                        if let Some(end) = attr_str[start + 11..].find('"') {
                                            comment = Some(attr_str[start + 11..start + 11 + end].to_string());
                                        }
                                    }
                                }
                                
                                if attr_str.contains("db_type") {
                                    // Extract db_type value between quotes
                                    if let Some(start) = attr_str.find("db_type = \"") {
                                        if let Some(end) = attr_str[start + 11..].find('"') {
                                            db_type = Some(attr_str[start + 11..start + 11 + end].to_string());
                                        }
                                    }
                                }
                                
                                if attr_str.contains("foreign_key") {
                                    // Extract foreign_key value between quotes
                                    if let Some(start) = attr_str.find("foreign_key = \"") {
                                        if let Some(end) = attr_str[start + 15..].find('"') {
                                            let fk_value = attr_str[start + 15..start + 15 + end].to_string();
                                            
                                            // Parse foreign key reference (table.column)
                                            if let Some(dot_pos) = fk_value.find('.') {
                                                let ref_table = fk_value[..dot_pos].to_string();
                                                let ref_column = fk_value[dot_pos + 1..].to_string();
                                                
                                                foreign_key = Some(crate::schema::types::ForeignKeyDefinition {
                                                    ref_table,
                                                    ref_column,
                                                    on_delete: None,
                                                    on_update: None,
                                                });
                                            }
                                        }
                                    }
                                }
                            }
                        }
                        
                        // Determine nullability from Option<T> type if not explicitly set
                        if !nullable && field_type.starts_with("Option < ") {
                            nullable = true;
                        }
                        
                        Some(FieldDefinition {
                            name: field_name,
                            rust_type: field_type,
                            db_type,
                            nullable,
                            primary_key,
                            unique,
                            default,
                            foreign_key,
                            comment,
                            attributes,
                        })
                    })
                    .collect()
            }
            _ => {
                return Err(Error::ModelRegistrationError(
                    format!("Only named fields are supported in struct: {}", struct_name)
                ));
            }
        };
        
        // Register the model
        let model_info = ModelInfo {
            name: struct_name.clone(),
            file_path: file_path.to_owned(),
            table_name,
            fields,
            attributes: HashMap::new(),
        };
        
        self.models.insert(struct_name, model_info);
        
        Ok(())
    }
    
    /// Extract table name from struct or attributes
    fn extract_table_name(
        &self,
        item_struct: &ItemStruct,
        struct_name: &str,
        naming_config: &crate::config::NamingConfig,
    ) -> Result<String> {
        // Check for explicit table name in attributes
        for attr in &item_struct.attrs {
            if attr.path().is_ident("schema_sync") {
                let attr_str = attr.to_token_stream().to_string();
                
                if attr_str.contains("table =") {
                    // Extract table name between quotes
                    if let Some(start) = attr_str.find("table = \"") {
                        if let Some(end) = attr_str[start + 9..].find('"') {
                            return Ok(attr_str[start + 9..start + 9 + end].to_string());
                        }
                    }
                }
            }
        }
        
        // Apply naming convention
        let table_name = apply_naming_convention(struct_name, &naming_config.table_style);
        
        // Apply pluralization if configured
        let final_name = if naming_config.pluralize_tables {
            use inflector::Inflector;
            table_name.to_plural()
        } else {
            table_name
        };
        
        Ok(final_name)
    }
    
    /// Convert registered models to database schema
    pub fn to_database_schema(&self, config: &Config) -> Result<DatabaseSchema> {
        let mut schema = DatabaseSchema::new(config.database.schema.clone());
        
        for (_, model_info) in &self.models {
            let mut table = Table::new(&model_info.table_name);
            
            // Convert fields to columns
            for field in &model_info.fields {
                // Map Rust type to database type
                let db_type = match &field.db_type {
                    Some(t) => t.clone(),
                    None => self.map_type_to_db_type(&field.rust_type, config)?,
                };
                
                let column = crate::schema::types::Column {
                    name: field.name.clone(),
                    data_type: db_type,
                    nullable: field.nullable,
                    default: field.default.clone(),
                    comment: field.comment.clone(),
                    is_unique: field.unique,
                    is_generated: false,
                    generation_expression: None,
                };
                
                table.add_column(column);
            }
            
            // Set primary key if defined
            let pk_fields: Vec<&FieldDefinition> = model_info.fields
                .iter()
                .filter(|f| f.primary_key)
                .collect();
                
            if !pk_fields.is_empty() {
                let pk_columns = pk_fields.iter().map(|f| f.name.clone()).collect();
                table.set_primary_key(crate::schema::types::PrimaryKey {
                    name: Some(format!("pk_{}", model_info.table_name)),
                    columns: pk_columns,
                });
            }
            
            // Add created_at and updated_at columns if configured
            if config.schema.add_created_at_column {
                let column_exists = table.columns.iter().any(|c| c.name == "created_at");
                
                if !column_exists {
                    table.add_column(crate::schema::types::Column {
                        name: "created_at".to_string(),
                        data_type: "TIMESTAMP WITH TIME ZONE".to_string(),
                        nullable: false,
                        default: Some("CURRENT_TIMESTAMP".to_string()),
                        comment: Some("Record creation timestamp".to_string()),
                        is_unique: false,
                        is_generated: false,
                        generation_expression: None,
                    });
                }
            }
            
            if config.schema.add_updated_at_column {
                let column_exists = table.columns.iter().any(|c| c.name == "updated_at");
                
                if !column_exists {
                    table.add_column(crate::schema::types::Column {
                        name: "updated_at".to_string(),
                        data_type: "TIMESTAMP WITH TIME ZONE".to_string(),
                        nullable: false,
                        default: Some("CURRENT_TIMESTAMP".to_string()),
                        comment: Some("Record last update timestamp".to_string()),
                        is_unique: false,
                        is_generated: false,
                        generation_expression: None,
                    });
                }
            }
            
            // Add indexes for unique and foreign key columns
            for field in &model_info.fields {
                // Add unique constraints
                if field.unique {
                    let index_name = format!("ix_{}_{}",
                        model_info.table_name,
                        field.name
                    );
                    
                    table.add_index(crate::schema::types::Index {
                        name: index_name,
                        columns: vec![field.name.clone()],
                        is_unique: true,
                        method: Some("btree".to_string()),
                    });
                }
                
                // Add foreign key constraints
                if let Some(fk) = &field.foreign_key {
                    // Generate foreign key name
                    let fk_name = crate::utils::get_foreign_key_name(
                        &config.naming.constraint_pattern,
                        &model_info.table_name,
                        &field.name,
                    );
                    
                    table.foreign_keys.push(crate::schema::types::ForeignKey {
                        name: fk_name,
                        columns: vec![field.name.clone()],
                        ref_table: fk.ref_table.clone(),
                        ref_columns: vec![fk.ref_column.clone()],
                        on_delete: fk.on_delete.clone(),
                        on_update: fk.on_update.clone(),
                    });
                    
                    // Add index for foreign key if configured
                    if config.schema.index_foreign_keys {
                        let index_name = format!("ix_{}_{}",
                            model_info.table_name,
                            field.name
                        );
                        
                        table.add_index(crate::schema::types::Index {
                            name: index_name,
                            columns: vec![field.name.clone()],
                            is_unique: false,
                            method: Some("btree".to_string()),
                        });
                    }
                }
            }
            
            schema.add_table(table);
        }
        
        Ok(schema)
    }
    
    /// Map Rust type to database type
    fn map_type_to_db_type(&self, rust_type: &str, config: &Config) -> Result<String> {
        // First check for custom type mappings
        if let Some(custom_mappings) = &config.type_mapping.custom {
            for mapping in custom_mappings {
                if mapping.rust_type == rust_type {
                    return Ok(mapping.db_type.clone());
                }
            }
        }
        
        // Then check for overrides
        if let Some(overrides) = &config.type_mapping.override_ {
            if let Some(db_type) = overrides.get(rust_type) {
                return Ok(db_type.clone());
            }
        }
        
        // Default mappings
        match rust_type {
            "String" | "&str" => Ok("VARCHAR(255)".to_string()),
            "i8" => Ok("SMALLINT".to_string()),
            "i16" => Ok("SMALLINT".to_string()),
            "i32" => Ok("INTEGER".to_string()),
            "i64" => Ok("BIGINT".to_string()),
            "u8" | "u16" | "u32" => Ok("INTEGER".to_string()),
            "u64" => Ok("BIGINT".to_string()),
            "f32" => Ok("REAL".to_string()),
            "f64" => Ok("DOUBLE PRECISION".to_string()),
            "bool" => Ok("BOOLEAN".to_string()),
            t if t.contains("Vec<u8>") => Ok("BYTEA".to_string()),
            t if t.contains("DateTime") => Ok("TIMESTAMP WITH TIME ZONE".to_string()),
            t if t.contains("NaiveDateTime") => Ok("TIMESTAMP".to_string()),
            t if t.contains("NaiveDate") => Ok("DATE".to_string()),
            t if t.contains("Uuid") => Ok("UUID".to_string()),
            t if t.contains("Decimal") => Ok("NUMERIC(20,6)".to_string()),
            t if t.contains("Json") || t.contains("Value") => Ok("JSONB".to_string()),
            _ => Err(Error::TypeMappingError(format!(
                "No mapping found for Rust type: {}", rust_type
            ))),
        }
    }
    
    /// Get all registered models
    pub fn get_models(&self) -> &HashMap<String, ModelInfo> {
        &self.models
    }
    
    /// Get a specific model by name
    pub fn get_model(&self, name: &str) -> Option<&ModelInfo> {
        self.models.get(name)
    }
}
$$--GLUE--$$
.\schema_sync\src\schema\analyzer.rs
$$--GLUE--$$
//! Database schema analyzer
//!
//! This module provides functionality to analyze an existing database schema.

use async_trait::async_trait;
use sqlx::{Any, MySql, Pool, Postgres, Sqlite};
use std::collections::HashMap;

use crate::db::connection::DatabaseConnection;
use crate::error::Result;
use crate::schema::types::{Column, DatabaseSchema, ForeignKey, Index, PrimaryKey, Table, View};

/// Schema analyzer trait
#[async_trait]
pub trait Analyzer {
    /// Analyze the database schema
    async fn analyze_schema(&self, schema_name: Option<&str>) -> Result<DatabaseSchema>;

    /// Analyze table definitions
    async fn analyze_tables(&self, schema_name: Option<&str>) -> Result<HashMap<String, Table>>;

    /// Analyze view definitions
    async fn analyze_views(&self, schema_name: Option<&str>) -> Result<HashMap<String, View>>;
}

/// Schema analyzer for database schema introspection
pub struct SchemaAnalyzer {
    connection: DatabaseConnection,
}

impl SchemaAnalyzer {
    /// Create a new schema analyzer
    pub fn new(connection: DatabaseConnection) -> Self {
        Self { connection }
    }

    /// Analyze the current database schema
    pub async fn analyze(&self) -> Result<DatabaseSchema> {
        match &self.connection {
            DatabaseConnection::Postgres(pool) => {
                PostgresAnalyzer { pool }
                    .analyze_schema(self.connection.get_schema())
                    .await
            }
            DatabaseConnection::MySql(pool) => {
                MySqlAnalyzer { pool }
                    .analyze_schema(self.connection.get_schema())
                    .await
            }
            DatabaseConnection::Sqlite(pool) => {
                SqliteAnalyzer { pool }
                    .analyze_schema(self.connection.get_schema())
                    .await
            }
            _ => Err(crate::error::Error::SchemaAnalysisError(
                "Unsupported database type".to_string(),
            )),
        }
    }
}

/// PostgreSQL schema analyzer
struct PostgresAnalyzer<'a> {
    pool: &'a Pool<Postgres>,
}

#[async_trait]
impl<'a> Analyzer for PostgresAnalyzer<'a> {
    async fn analyze_schema(&self, schema_name: Option<&str>) -> Result<DatabaseSchema> {
        let schema = schema_name.unwrap_or("public");
        let mut db_schema = DatabaseSchema::new(Some(schema.to_string()));

        // Get tables
        db_schema.tables = self.analyze_tables(Some(schema)).await?;

        // Get views
        db_schema.views = self.analyze_views(Some(schema)).await?;

        Ok(db_schema)
    }

    async fn analyze_tables(&self, schema_name: Option<&str>) -> Result<HashMap<String, Table>> {
        let schema = schema_name.unwrap_or("public");
        let mut tables = HashMap::new();

        // Query to get table names
        let table_rows = sqlx::query_unchecked!(
            r#"
            SELECT table_name 
            FROM information_schema.tables 
            WHERE table_schema = $1 AND table_type = 'BASE TABLE'
            "#,
            schema
        )
        .fetch_all(self.pool)
        .await?;

        for row in table_rows {
            let table_name = row.table_name;
            let mut table = Table::new(&table_name);

            // Get columns
            let column_rows = sqlx::query_unchecked!(
                r#"
                SELECT 
                    column_name, 
                    data_type, 
                    is_nullable, 
                    column_default,
                    character_maximum_length
                FROM information_schema.columns 
                WHERE table_schema = $1 AND table_name = $2
                ORDER BY ordinal_position
                "#,
                schema,
                table_name
            )
            .fetch_all(self.pool)
            .await?;

            for col in column_rows {
                let mut data_type = col.data_type;
                if let Some(max_length) = col.character_maximum_length {
                    if data_type == "character varying" {
                        data_type = format!("varchar({})", max_length);
                    }
                }

                let column = Column {
                    name: col.column_name,
                    data_type,
                    nullable: col.is_nullable == "YES",
                    default: col.column_default,
                    comment: None,
                    is_unique: false, // Will be updated when checking constraints
                    is_generated: false,
                    generation_expression: None,
                };

                table.add_column(column);
            }

            // Get primary key
            let pk_rows = sqlx::query_unchecked!(
                r#"
                SELECT
                    tc.constraint_name,
                    kcu.column_name
                FROM
                    information_schema.table_constraints tc
                JOIN information_schema.key_column_usage kcu
                    ON tc.constraint_name = kcu.constraint_name
                    AND tc.table_schema = kcu.table_schema
                WHERE
                    tc.constraint_type = 'PRIMARY KEY'
                    AND tc.table_schema = $1
                    AND tc.table_name = $2
                ORDER BY kcu.ordinal_position
                "#,
                schema,
                table_name
            )
            .fetch_all(self.pool)
            .await?;

            if !pk_rows.is_empty() {
                let pk_name = pk_rows[0].constraint_name.clone();
                let pk_columns = pk_rows.iter().map(|r| r.column_name.clone()).collect();

                table.set_primary_key(PrimaryKey {
                    name: Some(pk_name),
                    columns: pk_columns,
                });
            }

            // Get indexes
            let index_rows = sqlx::query_unchecked!(
                r#"
                SELECT
                    i.relname as index_name,
                    a.attname as column_name,
                    ix.indisunique as is_unique,
                    am.amname as index_method
                FROM
                    pg_index ix
                JOIN pg_class i ON i.oid = ix.indexrelid
                JOIN pg_class t ON t.oid = ix.indrelid
                JOIN pg_attribute a ON a.attrelid = t.oid AND a.attnum = ANY(ix.indkey)
                JOIN pg_namespace n ON n.oid = t.relnamespace
                JOIN pg_am am ON am.oid = i.relam
                WHERE
                    t.relname = $1
                    AND n.nspname = $2
                    AND NOT ix.indisprimary
                ORDER BY i.relname, a.attnum
                "#,
                table_name,
                schema
            )
            .fetch_all(self.pool)
            .await?;

            let mut indexes = HashMap::new();
            for row in index_rows {
                let index_name = row.index_name;
                let column_name = row.column_name;
                let is_unique = row.is_unique.unwrap_or(false);
                let method = row.index_method;

                indexes
                    .entry(index_name)
                    .or_insert_with(|| Index {
                        name: index_name.clone(),
                        columns: Vec::new(),
                        is_unique,
                        method: Some(method),
                    })
                    .columns
                    .push(column_name);
            }

            table.indexes = indexes.into_values().collect();

            // Get foreign keys
            let fk_rows = sqlx::query_unchecked!(
                r#"
            SELECT
                tc.constraint_name,
                kcu.column_name,
                ccu.table_name AS ref_table,
                ccu.column_name AS ref_column,
                rc.delete_rule,
                rc.update_rule
            FROM
                information_schema.table_constraints tc
            JOIN information_schema.key_column_usage kcu
                ON tc.constraint_name = kcu.constraint_name
                AND tc.table_schema = kcu.table_schema
            JOIN information_schema.constraint_column_usage ccu
                ON ccu.constraint_name = tc.constraint_name
                AND ccu.table_schema = tc.table_schema
            JOIN information_schema.referential_constraints rc
                ON tc.constraint_name = rc.constraint_name
                AND tc.table_schema = rc.constraint_schema
            WHERE
                tc.constraint_type = 'FOREIGN KEY'
                AND tc.table_schema = $1
                AND tc.table_name = $2
            ORDER BY tc.constraint_name, kcu.ordinal_position
            "#,
                schema,
                table_name
            )
            .fetch_all(self.pool)
            .await?;

            let mut foreign_keys = HashMap::new();
            for row in fk_rows {
                let fk_name = row.constraint_name;
                let column_name = row.column_name;
                let ref_table = row.ref_table;
                let ref_column = row.ref_column;
                let on_delete = row.delete_rule;
                let on_update = row.update_rule;

                foreign_keys
                    .entry(fk_name.clone())
                    .or_insert_with(|| ForeignKey {
                        name: fk_name,
                        columns: Vec::new(),
                        ref_table,
                        ref_columns: Vec::new(),
                        on_delete: Some(on_delete),
                        on_update: Some(on_update),
                    })
                    .columns
                    .push(column_name);

                foreign_keys
                    .get_mut(&fk_name)
                    .unwrap()
                    .ref_columns
                    .push(ref_column);
            }

            table.foreign_keys = foreign_keys.into_values().collect();

            tables.insert(table_name, table);
        }

        Ok(tables)
    }

    async fn analyze_views(&self, schema_name: Option<&str>) -> Result<HashMap<String, View>> {
        let schema = schema_name.unwrap_or("public");
        let mut views = HashMap::new();

        // Query to get view definitions
        let view_rows = sqlx::query_unchecked!(
            r#"
        SELECT table_name, view_definition, is_updatable
        FROM information_schema.views
        WHERE table_schema = $1
        "#,
            schema
        )
        .fetch_all(self.pool)
        .await?;

        for row in view_rows {
            let view_name = row.table_name;
            let view_definition = row.view_definition.unwrap_or_default();

            // Get view columns
            let column_rows = sqlx::query_unchecked!(
                r#"
            SELECT 
                column_name, 
                data_type, 
                is_nullable
            FROM information_schema.columns 
            WHERE table_schema = $1 AND table_name = $2
            ORDER BY ordinal_position
            "#,
                schema,
                view_name
            )
            .fetch_all(self.pool)
            .await?;

            let columns = column_rows
                .into_iter()
                .map(|col| Column {
                    name: col.column_name,
                    data_type: col.data_type,
                    nullable: col.is_nullable == "YES",
                    default: None,
                    comment: None,
                    is_unique: false,
                    is_generated: false,
                    generation_expression: None,
                })
                .collect();

            let view = View {
                name: view_name.clone(),
                definition: view_definition,
                columns,
                is_materialized: false, // Need separate query for materialized views
            };

            views.insert(view_name, view);
        }

        // Add materialized views
        let mat_view_rows = sqlx::query_unchecked!(
            r#"
        SELECT matviewname, definition
        FROM pg_matviews
        WHERE schemaname = $1
        "#,
            schema
        )
        .fetch_all(self.pool)
        .await?;

        for row in mat_view_rows {
            let view_name = row.matviewname;
            let view_definition = row.definition.unwrap_or_default();

            // Get view columns
            let column_rows = sqlx::query_unchecked!(
                r#"
            SELECT s
                column_name, 
                data_type, 
                is_nullable 
            FROM information_schema.columns 
            WHERE table_schema = $1 AND table_name = $2
            ORDER BY ordinal_position
            "#,
                schema,
                view_name
            )
            .fetch_all(self.pool)
            .await?;

            let columns = column_rows
                .into_iter()
                .map(|col| Column {
                    name: col.column_name,
                    data_type: col.data_type,
                    nullable: col.is_nullable == "YES",
                    default: None,
                    comment: None,
                    is_unique: false,
                    is_generated: false,
                    generation_expression: None,
                })
                .collect();

            let view = View {
                name: view_name.clone(),
                definition: view_definition,
                columns,
                is_materialized: true,
            };

            views.insert(view_name, view);
        }

        Ok(views)
    }
}

// Similar implementations for MySQL and SQLite analyzers
// (abbreviated here for brevity - would implement specific versions for each database type)

struct MySqlAnalyzer<'a> {
    pool: &'a Pool<MySql>,
}

#[async_trait]
impl<'a> Analyzer for MySqlAnalyzer<'a> {
    async fn analyze_schema(&self, schema_name: Option<&str>) -> Result<DatabaseSchema> {
        // MySQL-specific implementation
        todo!("Implement MySQL schema analysis")
    }

    async fn analyze_tables(&self, schema_name: Option<&str>) -> Result<HashMap<String, Table>> {
        // MySQL-specific implementation
        todo!("Implement MySQL table analysis")
    }

    async fn analyze_views(&self, schema_name: Option<&str>) -> Result<HashMap<String, View>> {
        // MySQL-specific implementation
        todo!("Implement MySQL view analysis")
    }
}

struct SqliteAnalyzer<'a> {
    pool: &'a Pool<Sqlite>,
}

#[async_trait]
impl<'a> Analyzer for SqliteAnalyzer<'a> {
    async fn analyze_schema(&self, schema_name: Option<&str>) -> Result<DatabaseSchema> {
        // SQLite-specific implementation
        todo!("Implement SQLite schema analysis")
    }

    async fn analyze_tables(&self, schema_name: Option<&str>) -> Result<HashMap<String, Table>> {
        // SQLite-specific implementation
        todo!("Implement SQLite table analysis")
    }

    async fn analyze_views(&self, schema_name: Option<&str>) -> Result<HashMap<String, View>> {
        // SQLite-specific implementation
        todo!("Implement SQLite view analysis")
    }
}

$$--GLUE--$$
.\schema_sync\src\schema\diff.rs
$$--GLUE--$$
//! Schema difference calculator
//!
//! This module compares two database schemas and calculates the differences

use std::collections::{HashMap, HashSet};

use crate::config::SchemaConfig;
use crate::error::Result;
use crate::schema::types::{Column, DatabaseSchema, Table};

/// Represents changes needed to synchronize two schemas
#[derive(Debug, Clone)]
pub struct SchemaDiff {
    pub tables_to_create: Vec<Table>,
    pub tables_to_drop: Vec<String>,
    pub columns_to_add: HashMap<String, Vec<Column>>,
    pub columns_to_drop: HashMap<String, Vec<String>>,
    pub columns_to_alter: HashMap<String, Vec<ColumnChange>>,
    pub indices_to_create: HashMap<String, Vec<String>>,
    pub indices_to_drop: HashMap<String, Vec<String>>,
    pub foreign_keys_to_create: HashMap<String, Vec<String>>,
    pub foreign_keys_to_drop: HashMap<String, Vec<String>>,
}

impl SchemaDiff {
    /// Generate a schema diff between two database schemas
    pub fn generate(
        current_schema: DatabaseSchema, 
        target_schema: DatabaseSchema, 
        schema_config: &SchemaConfig
    ) -> Self {
        // Tables to create (in target but not in current)
        let tables_to_create = target_schema
            .tables
            .values()
            .filter(|table| !current_schema.tables.contains_key(&table.name))
            .cloned()
            .collect();
            
        // Tables to drop (in current but not in target)
        let tables_to_drop = if schema_config.allow_table_removal {
            current_schema
                .tables
                .keys()
                .filter(|&name| !target_schema.tables.contains_key(name))
                .cloned()
                .collect()
        } else {
            Vec::new()
        };
        
        // Process tables that exist in both schemas for column changes
        let mut columns_to_add = HashMap::new();
        let mut columns_to_drop = HashMap::new();
        let mut columns_to_alter = HashMap::new();
        
        for (table_name, target_table) in &target_schema.tables {
            if let Some(current_table) = current_schema.tables.get(table_name) {
                // Map columns by name for easier comparison
                let current_columns: HashMap<String, &Column> = current_table
                    .columns
                    .iter()
                    .map(|col| (col.name.clone(), col))
                    .collect();
                
                let target_columns: HashMap<String, &Column> = target_table
                    .columns
                    .iter()
                    .map(|col| (col.name.clone(), col))
                    .collect();
                
                // Columns to add (in target but not in current)
                let add_columns: Vec<Column> = target_table
                    .columns
                    .iter()
                    .filter(|col| !current_columns.contains_key(&col.name))
                    .cloned()
                    .collect();
                
                if !add_columns.is_empty() {
                    columns_to_add.insert(table_name.clone(), add_columns);
                }
                
                // Columns to drop (in current but not in target)
                if schema_config.allow_column_removal {
                    let drop_columns: Vec<String> = current_table
                        .columns
                        .iter()
                        .filter(|col| !target_columns.contains_key(&col.name))
                        .map(|col| col.name.clone())
                        .collect();
                    
                    if !drop_columns.is_empty() {
                        columns_to_drop.insert(table_name.clone(), drop_columns);
                    }
                }
                
                // Columns to alter (different definition in target)
                let alter_columns: Vec<ColumnChange> = target_table
                    .columns
                    .iter()
                    .filter_map(|target_col| {
                        if let Some(current_col) = current_columns.get(&target_col.name) {
                            if Self::column_needs_alteration(current_col, target_col, schema_config) {
                                Some(ColumnChange {
                                    column_name: target_col.name.clone(),
                                    from: (*current_col).clone(),
                                    to: target_col.clone(),
                                })
                            } else {
                                None
                            }
                        } else {
                            None
                        }
                    })
                    .collect();
                
                if !alter_columns.is_empty() {
                    columns_to_alter.insert(table_name.clone(), alter_columns);
                }
            }
        }
        
        // TODO: Implement index and foreign key diff logic
        
        Self {
            tables_to_create,
            tables_to_drop,
            columns_to_add,
            columns_to_drop,
            columns_to_alter,
            indices_to_create: HashMap::new(),
            indices_to_drop: HashMap::new(),
            foreign_keys_to_create: HashMap::new(),
            foreign_keys_to_drop: HashMap::new(),
        }
    }
    
    /// Check if a column needs to be altered
    fn column_needs_alteration(
        current: &Column, 
        target: &Column, 
        schema_config: &SchemaConfig
    ) -> bool {
        // Type different
        if current.data_type != target.data_type {
            return true;
        }
        
        // Nullability different
        if current.nullable != target.nullable {
            return true;
        }
        
        // Default value different
        if current.default != target.default {
            return true;
        }
        
        // Handle uniqueness changes
        if current.is_unique != target.is_unique {
            return true;
        }
        
        false
    }
    
    /// Check if the diff is empty (no changes needed)
    pub fn is_empty(&self) -> bool {
        self.tables_to_create.is_empty()
            && self.tables_to_drop.is_empty()
            && self.columns_to_add.is_empty()
            && self.columns_to_drop.is_empty()
            && self.columns_to_alter.is_empty()
            && self.indices_to_create.is_empty()
            && self.indices_to_drop.is_empty()
            && self.foreign_keys_to_create.is_empty()
            && self.foreign_keys_to_drop.is_empty()
    }
}

/// Represents a column change
#[derive(Debug, Clone)]
pub struct ColumnChange {
    pub column_name: String,
    pub from: Column,
    pub to: Column,
}
$$--GLUE--$$
.\schema_sync\src\schema\generator.rs
$$--GLUE--$$
//! Migration generator
//!
//! This module generates SQL migration statements from schema diffs

use crate::config::Config;
use crate::error::Result;
use crate::schema::diff::{ColumnChange, SchemaDiff};
use crate::schema::types::{Column, Table};

/// Migration SQL generator
pub struct MigrationGenerator<'a> {
    config: &'a Config,
}

impl<'a> MigrationGenerator<'a> {
    /// Create a new migration generator
    pub fn new(config: &'a Config) -> Self {
        Self { config }
    }
    
    /// Generate migration SQL from a schema diff
    pub async fn generate_migration_sql(&self, diff: &SchemaDiff) -> Result<Vec<String>> {
        let mut migrations = Vec::new();
        
        // Handle table creation
        for table in &diff.tables_to_create {
            migrations.push(self.generate_create_table_sql(table)?);
        }
        
        // Handle table deletion
        for table_name in &diff.tables_to_drop {
            migrations.push(self.generate_drop_table_sql(table_name)?);
        }
        
        // Handle column additions
        for (table_name, columns) in &diff.columns_to_add {
            migrations.push(self.generate_add_columns_sql(table_name, columns)?);
        }
        
        // Handle column deletions
        for (table_name, column_names) in &diff.columns_to_drop {
            migrations.push(self.generate_drop_columns_sql(table_name, column_names)?);
        }
        
        // Handle column modifications
        for (table_name, column_changes) in &diff.columns_to_alter {
            migrations.push(self.generate_alter_columns_sql(table_name, column_changes)?);
        }
        
        // TODO: Handle index and foreign key changes
        
        Ok(migrations)
    }
    
    /// Generate SQL to create a table
    fn generate_create_table_sql(&self, table: &Table) -> Result<String> {
        let db_type = &self.config.database.driver;
        
        match db_type.as_str() {
            "postgres" => self.generate_postgres_create_table_sql(table),
            "mysql" => self.generate_mysql_create_table_sql(table),
            "sqlite" => self.generate_sqlite_create_table_sql(table),
            _ => Err(crate::error::Error::MigrationError(format!(
                "Unsupported database type: {}", db_type
            ))),
        }
    }
    
    /// Generate PostgreSQL-specific table creation SQL
    fn generate_postgres_create_table_sql(&self, table: &Table) -> Result<String> {
        let mut sql = format!("CREATE TABLE IF NOT EXISTS {} (\n", table.name);
        
        // Add columns
        let mut column_defs = Vec::new();
        for column in &table.columns {
            let nullable = if column.nullable { "NULL" } else { "NOT NULL" };
            let default = if let Some(default_val) = &column.default {
                format!(" DEFAULT {}", default_val)
            } else {
                String::new()
            };
            
            column_defs.push(format!(
                "  {} {}{} {}",
                column.name,
                column.data_type,
                default,
                nullable
            ));
        }
        
        // Add primary key
        if let Some(pk) = &table.primary_key {
            let columns = pk.columns.join(", ");
            column_defs.push(format!("  PRIMARY KEY ({})", columns));
        }
        
        sql.push_str(&column_defs.join(",\n"));
        sql.push_str("\n);\n");
        
        // Add indices
        for index in &table.indexes {
            let unique = if index.is_unique { "UNIQUE " } else { "" };
            let method = index.method.as_deref().unwrap_or("btree");
            let columns = index.columns.join(", ");
            
            sql.push_str(&format!(
                "CREATE {}INDEX {} ON {} USING {} ({});\n",
                unique,
                index.name,
                table.name,
                method,
                columns
            ));
        }
        
        // Add foreign keys
        for fk in &table.foreign_keys {
            let columns = fk.columns.join(", ");
            let ref_columns = fk.ref_columns.join(", ");
            let on_delete = fk.on_delete.as_deref().unwrap_or("NO ACTION");
            let on_update = fk.on_update.as_deref().unwrap_or("NO ACTION");
            
            sql.push_str(&format!(
                "ALTER TABLE {} ADD CONSTRAINT {} FOREIGN KEY ({}) REFERENCES {} ({}) ON DELETE {} ON UPDATE {};\n",
                table.name,
                fk.name,
                columns,
                fk.ref_table,
                ref_columns,
                on_delete,
                on_update
            ));
        }
        
        Ok(sql)
    }
    
    // Generate MySQL-specific table creation SQL
    fn generate_mysql_create_table_sql(&self, table: &Table) -> Result<String> {
        // MySQL implementation
        // (abbreviated for brevity)
        todo!("Implement MySQL table creation SQL")
    }
    
    // Generate SQLite-specific table creation SQL
    fn generate_sqlite_create_table_sql(&self, table: &Table) -> Result<String> {
        // SQLite implementation
        // (abbreviated for brevity)
        todo!("Implement SQLite table creation SQL")
    }
    
    /// Generate SQL to drop a table
    fn generate_drop_table_sql(&self, table_name: &str) -> Result<String> {
        Ok(format!("DROP TABLE IF EXISTS {};", table_name))
    }
    
    /// Generate SQL to add columns to a table
    fn generate_add_columns_sql(&self, table_name: &str, columns: &[Column]) -> Result<String> {
        let db_type = &self.config.database.driver;
        
        match db_type.as_str() {
            "postgres" => {
                let mut sql = String::new();
                
                for column in columns {
                    let nullable = if column.nullable { "NULL" } else { "NOT NULL" };
                    let default = if let Some(default_val) = &column.default {
                        format!(" DEFAULT {}", default_val)
                    } else {
                        String::new()
                    };
                    
                    sql.push_str(&format!(
                        "ALTER TABLE {} ADD COLUMN {} {}{} {};\n",
                        table_name,
                        column.name,
                        column.data_type,
                        default,
                        nullable
                    ));
                }
                
                Ok(sql)
            }
            "mysql" | "sqlite" => {
                // Abbreviated for brevity
                todo!("Implement for MySQL/SQLite")
            }
            _ => Err(crate::error::Error::MigrationError(format!(
                "Unsupported database type: {}", db_type
            ))),
        }
    }
    
    /// Generate SQL to drop columns from a table
    fn generate_drop_columns_sql(&self, table_name: &str, column_names: &[String]) -> Result<String> {
        let db_type = &self.config.database.driver;
        
        match db_type.as_str() {
            "postgres" => {
                let mut sql = String::new();
                
                for column_name in column_names {
                    sql.push_str(&format!(
                        "ALTER TABLE {} DROP COLUMN {};\n",
                        table_name,
                        column_name
                    ));
                }
                
                Ok(sql)
            }
            "mysql" | "sqlite" => {
                // Abbreviated for brevity
                todo!("Implement for MySQL/SQLite")
            }
            _ => Err(crate::error::Error::MigrationError(format!(
                "Unsupported database type: {}", db_type
            ))),
        }
    }
    
    /// Generate SQL to alter columns in a table
    fn generate_alter_columns_sql(
        &self,
        table_name: &str,
        column_changes: &[ColumnChange],
    ) -> Result<String> {
        let db_type = &self.config.database.driver;
        
        match db_type.as_str() {
            "postgres" => {
                let mut sql = String::new();
                
                for change in column_changes {
                    // Alter column type
                    if change.from.data_type != change.to.data_type {
                        sql.push_str(&format!(
                            "ALTER TABLE {} ALTER COLUMN {} TYPE {} USING {}::{};\n",
                            table_name,
                            change.column_name,
                            change.to.data_type,
                            change.column_name,
                            change.to.data_type
                        ));
                    }
                    
                    // Alter nullability
                    if change.from.nullable != change.to.nullable {
                        if change.to.nullable {
                            sql.push_str(&format!(
                                "ALTER TABLE {} ALTER COLUMN {} DROP NOT NULL;\n",
                                table_name,
                                change.column_name
                            ));
                        } else {
                            sql.push_str(&format!(
                                "ALTER TABLE {} ALTER COLUMN {} SET NOT NULL;\n",
                                table_name,
                                change.column_name
                            ));
                        }
                    }
                    
                    // Alter default value
                    if change.from.default != change.to.default {
                        if let Some(default_val) = &change.to.default {
                            sql.push_str(&format!(
                                "ALTER TABLE {} ALTER COLUMN {} SET DEFAULT {};\n",
                                table_name,
                                change.column_name,
                                default_val
                            ));
                        } else {
                            sql.push_str(&format!(
                                "ALTER TABLE {} ALTER COLUMN {} DROP DEFAULT;\n",
                                table_name,
                                change.column_name
                            ));
                        }
                    }
                }
                
                Ok(sql)
            }
            "mysql" | "sqlite" => {
                // Abbreviated for brevity
                todo!("Implement for MySQL/SQLite")
            }
            _ => Err(crate::error::Error::MigrationError(format!(
                "Unsupported database type: {}", db_type
            ))),
        }
    }
}
$$--GLUE--$$
.\schema_sync\src\schema\mod.rs
$$--GLUE--$$
//! Schema module for SchemaSync
//!
//! This module handles database schema analysis, comparison, and generation.

pub mod analyzer;
pub mod diff;
pub mod generator;
pub mod types;

// Re-export key types
pub use analyzer::SchemaAnalyzer;
pub use diff::{ColumnChange, SchemaDiff};
pub use generator::MigrationGenerator;
pub use types::{
    Column, Constraint, DatabaseSchema, FieldDefinition, ForeignKey, 
    ForeignKeyDefinition, Index, PrimaryKey, Table, View,
};
$$--GLUE--$$
.\schema_sync\src\schema\types.rs
$$--GLUE--$$
//! Type definitions for database schema objects

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

/// Represents a complete database schema
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DatabaseSchema {
    pub tables: HashMap<String, Table>,
    pub views: HashMap<String, View>,
    pub schema_name: Option<String>,
}

impl DatabaseSchema {
    /// Create a new empty database schema
    pub fn new(schema_name: Option<String>) -> Self {
        Self {
            tables: HashMap::new(),
            views: HashMap::new(),
            schema_name,
        }
    }
    
    /// Add a table to the schema
    pub fn add_table(&mut self, table: Table) {
        self.tables.insert(table.name.clone(), table);
    }
    
    /// Add a view to the schema
    pub fn add_view(&mut self, view: View) {
        self.views.insert(view.name.clone(), view);
    }
}

/// Represents a database table
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Table {
    pub name: String,
    pub columns: Vec<Column>,
    pub primary_key: Option<PrimaryKey>,
    pub indexes: Vec<Index>,
    pub foreign_keys: Vec<ForeignKey>,
    pub constraints: Vec<Constraint>,
    pub comment: Option<String>,
}

impl Table {
    /// Create a new table with the given name
    pub fn new(name: &str) -> Self {
        Self {
            name: name.to_string(),
            columns: Vec::new(),
            primary_key: None,
            indexes: Vec::new(),
            foreign_keys: Vec::new(),
            constraints: Vec::new(),
            comment: None,
        }
    }
    
    /// Add a column to the table
    pub fn add_column(&mut self, column: Column) {
        self.columns.push(column);
    }
    
    /// Set the primary key for the table
    pub fn set_primary_key(&mut self, pk: PrimaryKey) {
        self.primary_key = Some(pk);
    }
    
    /// Add an index to the table
    pub fn add_index(&mut self, index: Index) {
        self.indexes.push(index);
    }
    
    /// Add a foreign key to the table
    pub fn add_foreign_key(&mut self, fk: ForeignKey) {
        self.foreign_keys.push(fk);
    }
}

/// Represents a database column
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Column {
    pub name: String,
    pub data_type: String,
    pub nullable: bool,
    pub default: Option<String>,
    pub comment: Option<String>,
    pub is_unique: bool,
    pub is_generated: bool,
    pub generation_expression: Option<String>,
}

impl Column {
    /// Create a new column with the given name and type
    pub fn new(name: &str, data_type: &str) -> Self {
        Self {
            name: name.to_string(),
            data_type: data_type.to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        }
    }
    
    /// Set whether the column is nullable
    pub fn nullable(mut self, nullable: bool) -> Self {
        self.nullable = nullable;
        self
    }
    
    /// Set a default value for the column
    pub fn default(mut self, default: &str) -> Self {
        self.default = Some(default.to_string());
        self
    }
}

/// Represents a primary key constraint
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PrimaryKey {
    pub name: Option<String>,
    pub columns: Vec<String>,
}

/// Represents an index
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Index {
    pub name: String,
    pub columns: Vec<String>,
    pub is_unique: bool,
    pub method: Option<String>,
}

/// Represents a foreign key constraint
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ForeignKey {
    pub name: String,
    pub columns: Vec<String>,
    pub ref_table: String,
    pub ref_columns: Vec<String>,
    pub on_delete: Option<String>,
    pub on_update: Option<String>,
}

/// Represents a general constraint
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Constraint {
    pub name: String,
    pub definition: String,
    pub constraint_type: String,
}

/// Represents a database view
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct View {
    pub name: String,
    pub definition: String,
    pub columns: Vec<Column>,
    pub is_materialized: bool,
}

/// Represents a field definition from a Rust model
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FieldDefinition {
    pub name: String,
    pub rust_type: String,
    pub db_type: Option<String>,
    pub nullable: bool,
    pub primary_key: bool,
    pub unique: bool,
    pub default: Option<String>,
    pub foreign_key: Option<ForeignKeyDefinition>,
    pub comment: Option<String>,
    pub attributes: HashMap<String, String>,
}

/// Represents a foreign key definition from a Rust model
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ForeignKeyDefinition {
    pub ref_table: String,
    pub ref_column: String,
    pub on_delete: Option<String>,
    pub on_update: Option<String>,
}
$$--GLUE--$$
.\schema_sync\src\tests.rs
$$--GLUE--$$
//! Tests for SchemaSync
//!
//! This file contains unit and integration tests for the SchemaSync library.

#[cfg(test)]
mod tests {
    use std::path::PathBuf;
    use std::fs;
    use std::collections::HashMap;
    use tempfile::tempdir;
    use rstest::*;
    use pretty_assertions::assert_eq;
    
    use schema_sync::{
        Config, DatabaseConnection, ModelRegistry, SchemaAnalyzer, 
        SchemaDiff, MigrationGenerator, Error
    };
    use schema_sync::schema::types::{
        Column, DatabaseSchema, FieldDefinition, ForeignKey, 
        Index, PrimaryKey, Table, View
    };
    use schema_sync::models::SchemaSyncModel;
    use schema_sync::utils::naming;

    // Helper function to create a test configuration
    fn test_config() -> Config {
        let config_str = r###"
        [database]
        driver = "postgres"
        url = "postgres://postgres:password@localhost:5432/schema_sync_test"
        pool_size = 5
        timeout_seconds = 10
        schema = "public"
        enable_ssl = false

        [migrations]
        directory = "./test_migrations"
        naming = "timestamp_description"
        auto_generate = true
        auto_apply = false
        transaction_per_migration = true
        dry_run = true
        backup_before_migrate = false
        history_table = "schema_sync_history"

        [models]
        paths = ["./tests/models"]
        exclude_paths = []
        attributes = ["#[schema_sync]"]
        recursive_scan = true
        derive_macros = ["Serialize", "Deserialize"]

        [schema]
        strict_mode = true
        allow_column_removal = false
        allow_table_removal = false
        default_nullable = false
        index_foreign_keys = true
        unique_constraints_as_indices = true
        add_updated_at_column = true
        add_created_at_column = true

        [naming]
        table_style = "snake_case"
        column_style = "snake_case"
        index_pattern = "ix_{table}_{columns}"
        constraint_pattern = "fk_{table}_{column}"
        pluralize_tables = true
        ignore_case_conflicts = false

        [type_mapping]
        custom = [
          { rust_type = "chrono::DateTime<chrono::Utc>", db_type = "TIMESTAMP WITH TIME ZONE" },
          { rust_type = "uuid::Uuid", db_type = "UUID" }
        ]
        "###;
        
        toml::from_str(config_str).expect("Failed to parse test config")
    }

    #[test]
    fn test_naming_conventions() {
        assert_eq!(naming::apply_naming_convention("UserProfile", "snake_case"), "user_profile");
        assert_eq!(naming::apply_naming_convention("user_profile", "camel_case"), "userProfile");
        assert_eq!(naming::apply_naming_convention("user_profile", "pascal_case"), "UserProfile");
        assert_eq!(naming::apply_naming_convention("UserProfile", "kebab_case"), "user-profile");
        assert_eq!(naming::apply_naming_convention("UserProfile", "screaming_snake_case"), "USER_PROFILE");
        
        assert_eq!(
            naming::get_table_name("UserProfile", "snake_case", true),
            "user_profiles"
        );
        
        assert_eq!(
            naming::get_column_name("firstName", "snake_case"),
            "first_name"
        );
        
        assert_eq!(
            naming::get_index_name("ix_{table}_{columns}", "users", &vec!["email".to_string()]),
            "ix_users_email"
        );
        
        assert_eq!(
            naming::get_foreign_key_name("fk_{table}_{column}", "posts", "author_id"),
            "fk_posts_author_id"
        );
    }
    
    #[test]
    fn test_config_loading() {
        let config = test_config();
        
        assert_eq!(config.database.driver, "postgres");
        assert_eq!(config.migrations.history_table, "schema_sync_history");
        assert_eq!(config.schema.add_created_at_column, true);
        assert_eq!(config.naming.pluralize_tables, true);
    }
    
    #[test]
    fn test_type_mapping() {
        struct TestModel;
        
        impl SchemaSyncModel for TestModel {
            fn get_table_name() -> String {
                "test_models".to_string()
            }
            
            fn get_field_definitions() -> Vec<FieldDefinition> {
                vec![
                    FieldDefinition {
                        name: "id".to_string(),
                        rust_type: "i32".to_string(),
                        db_type: None,
                        nullable: false,
                        primary_key: true,
                        unique: false,
                        default: None,
                        foreign_key: None,
                        comment: None,
                        attributes: HashMap::new(),
                    },
                    FieldDefinition {
                        name: "name".to_string(),
                        rust_type: "String".to_string(),
                        db_type: None,
                        nullable: false,
                        primary_key: false,
                        unique: true,
                        default: None,
                        foreign_key: None,
                        comment: None,
                        attributes: HashMap::new(),
                    },
                ]
            }
            
            fn register_with_schema_sync() {}
        }
        
        let config = test_config();
        let registry = ModelRegistry::new(&config.models);
        
        // Test default mappings
        assert_eq!(
            registry.map_type_to_db_type("i32", &config).unwrap(),
            "INTEGER"
        );
        assert_eq!(
            registry.map_type_to_db_type("String", &config).unwrap(),
            "VARCHAR(255)"
        );
        assert_eq!(
            registry.map_type_to_db_type("bool", &config).unwrap(),
            "BOOLEAN"
        );
        
        // Test custom mappings
        assert_eq!(
            registry.map_type_to_db_type("chrono::DateTime<chrono::Utc>", &config).unwrap(),
            "TIMESTAMP WITH TIME ZONE"
        );
        assert_eq!(
            registry.map_type_to_db_type("uuid::Uuid", &config).unwrap(),
            "UUID"
        );
    }
    
    #[test]
    fn test_schema_diff_generation() {
        // Create current schema
        let mut current_schema = DatabaseSchema::new(Some("public".to_string()));
        
        let mut users_table = Table::new("users");
        users_table.add_column(Column {
            name: "id".to_string(),
            data_type: "INTEGER".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        users_table.add_column(Column {
            name: "name".to_string(),
            data_type: "VARCHAR(255)".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        users_table.set_primary_key(PrimaryKey {
            name: Some("pk_users".to_string()),
            columns: vec!["id".to_string()],
        });
        
        current_schema.add_table(users_table);
        
        // Create target schema (with changes)
        let mut target_schema = DatabaseSchema::new(Some("public".to_string()));
        
        let mut users_table = Table::new("users");
        users_table.add_column(Column {
            name: "id".to_string(),
            data_type: "INTEGER".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        users_table.add_column(Column {
            name: "name".to_string(),
            data_type: "VARCHAR(255)".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        // New column
        users_table.add_column(Column {
            name: "email".to_string(),
            data_type: "VARCHAR(255)".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: true,
            is_generated: false,
            generation_expression: None,
        });
        users_table.set_primary_key(PrimaryKey {
            name: Some("pk_users".to_string()),
            columns: vec!["id".to_string()],
        });
        
        target_schema.add_table(users_table);
        
        // New table
        let mut posts_table = Table::new("posts");
        posts_table.add_column(Column {
            name: "id".to_string(),
            data_type: "INTEGER".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        posts_table.add_column(Column {
            name: "title".to_string(),
            data_type: "VARCHAR(255)".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        posts_table.add_column(Column {
            name: "user_id".to_string(),
            data_type: "INTEGER".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        posts_table.set_primary_key(PrimaryKey {
            name: Some("pk_posts".to_string()),
            columns: vec!["id".to_string()],
        });
        posts_table.foreign_keys.push(ForeignKey {
            name: "fk_posts_user_id".to_string(),
            columns: vec!["user_id".to_string()],
            ref_table: "users".to_string(),
            ref_columns: vec!["id".to_string()],
            on_delete: Some("CASCADE".to_string()),
            on_update: Some("CASCADE".to_string()),
        });
        
        target_schema.add_table(posts_table);
        
        // Generate diff
        let config = test_config();
        let diff = SchemaDiff::generate(current_schema, target_schema, &config.schema);
        
        // Verify diff
        assert_eq!(diff.tables_to_create.len(), 1);
        assert_eq!(diff.tables_to_create[0].name, "posts");
        
        assert_eq!(diff.tables_to_drop.len(), 0); // No table removal allowed
        
        assert_eq!(diff.columns_to_add.len(), 1);
        assert!(diff.columns_to_add.contains_key("users"));
        assert_eq!(diff.columns_to_add["users"].len(), 1);
        assert_eq!(diff.columns_to_add["users"][0].name, "email");
        
        assert_eq!(diff.columns_to_drop.len(), 0); // No column removal allowed
    }
    
    #[test]
    fn test_migration_generator() {
        // Create a simple schema diff
        let mut diff = SchemaDiff {
            tables_to_create: Vec::new(),
            tables_to_drop: Vec::new(),
            columns_to_add: HashMap::new(),
            columns_to_drop: HashMap::new(),
            columns_to_alter: HashMap::new(),
            indices_to_create: HashMap::new(),
            indices_to_drop: HashMap::new(),
            foreign_keys_to_create: HashMap::new(),
            foreign_keys_to_drop: HashMap::new(),
        };
        
        // Add a table to create
        let mut users_table = Table::new("users");
        users_table.add_column(Column {
            name: "id".to_string(),
            data_type: "INTEGER".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        users_table.add_column(Column {
            name: "name".to_string(),
            data_type: "VARCHAR(255)".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: false,
            is_generated: false,
            generation_expression: None,
        });
        users_table.set_primary_key(PrimaryKey {
            name: Some("pk_users".to_string()),
            columns: vec!["id".to_string()],
        });
        
        diff.tables_to_create.push(users_table);
        
        // Add a column to add
        let email_column = Column {
            name: "email".to_string(),
            data_type: "VARCHAR(255)".to_string(),
            nullable: false,
            default: None,
            comment: None,
            is_unique: true,
            is_generated: false,
            generation_expression: None,
        };
        
        diff.columns_to_add.insert("users".to_string(), vec![email_column]);
        
        // Generate migrations
        let config = test_config();
        let generator = MigrationGenerator::new(&config);
        
        #[cfg(feature = "tokio")]
        {
            let runtime = tokio::runtime::Runtime::new().unwrap();
            let migrations = runtime.block_on(generator.generate_migration_sql(&diff)).unwrap();
            
            assert_eq!(migrations.len(), 2);
            assert!(migrations[0].contains("CREATE TABLE IF NOT EXISTS users"));
            assert!(migrations[1].contains("ALTER TABLE users ADD COLUMN email VARCHAR(255) NOT NULL"));
        }
    }
    
    #[rstest]
    #[case("snake_case", "UserProfile", "user_profile")]
    #[case("camel_case", "user_profile", "userProfile")]
    #[case("pascal_case", "user_profile", "UserProfile")]
    #[case("kebab_case", "UserProfile", "user-profile")]
    fn test_naming_convention_variations(#[case] style: &str, #[case] input: &str, #[case] expected: &str) {
        assert_eq!(naming::apply_naming_convention(input, style), expected);
    }
    
    #[rstest]
    #[case(true, "user", "users")]
    #[case(false, "user", "user")]
    #[case(true, "activity", "activities")]
    #[case(true, "category", "categories")]
    fn test_pluralization(#[case] pluralize: bool, #[case] input: &str, #[case] expected: &str) {
        assert_eq!(naming::get_table_name(input, "snake_case", pluralize), expected);
    }
    
    #[test]
    fn test_identifier_conflicts() {
        let names = vec![
            "User".to_string(),
            "user".to_string(),
            "admin".to_string(),
        ];
        
        // With case sensitivity
        assert!(naming::check_identifier_conflicts(&names, false).is_none());
        
        // Without case sensitivity
        let conflict = naming::check_identifier_conflicts(&names, true);
        assert!(conflict.is_some());
        let (name1, name2) = conflict.unwrap();
        assert!(name1 == "User" || name1 == "user");
        assert!(name2 == "User" || name2 == "user");
        assert_ne!(name1, name2);
    }
    
    #[test]
    fn test_sanitize_identifier() {
        assert_eq!(naming::sanitize_identifier("user-name"), "user_name");
        assert_eq!(naming::sanitize_identifier("123user"), "_123user");
        assert_eq!(naming::sanitize_identifier("user.name"), "user_name");
        assert_eq!(naming::sanitize_identifier("user@name"), "user_name");
    }
    
    #[test]
    fn test_truncate_identifier() {
        let long_name = "this_is_a_very_long_identifier_that_exceeds_database_limits";
        let truncated = naming::truncate_identifier(long_name, 30);
        
        assert_eq!(truncated.len(), 30);
        assert!(truncated.starts_with("this_is_a_very_long_identi"));
        assert!(truncated.contains("_"));
    }
    
    // Integration tests that require a database connection
    #[cfg(feature = "integration_tests")]
    mod integration_tests {
        use super::*;
        use schema_sync::{SchemaSyncClient, init};
        
        // These tests require a PostgreSQL database
        // They are only run when the "integration_tests" feature is enabled
        
        #[test]
        fn test_schema_analyzer() {
            let config = test_config();
            
            #[cfg(feature = "tokio")]
            {
                let runtime = tokio::runtime::Runtime::new().unwrap();
                
                runtime.block_on(async {
                    let conn = DatabaseConnection::connect(&config.database).await.unwrap();
                    let analyzer = SchemaAnalyzer::new(conn);
                    
                    let schema = analyzer.analyze().await.unwrap();
                    
                    // Verify schema contains expected tables
                    // This depends on the test database setup
                    assert!(schema.tables.contains_key("schema_sync_history"));
                });
            }
        }
        
        #[test]
        fn test_end_to_end_workflow() {
            // Create temporary directory for test models
            let temp_dir = tempdir().unwrap();
            let models_dir = temp_dir.path().join("models");
            fs::create_dir_all(&models_dir).unwrap();
            
            // Create test model file
            let model_content = r#"
            use serde::{Serialize, Deserialize};
            use chrono::{DateTime, Utc};
            use uuid::Uuid;
            
            #[derive(Serialize, Deserialize)]
            #[schema_sync]
            pub struct TestModel {
                #[schema_sync_field(primary_key = true)]
                pub id: i32,
                
                pub name: String,
                
                #[schema_sync_field(unique = true)]
                pub code: String,
                
                #[schema_sync_field(nullable = true)]
                pub description: Option<String>,
            }
            "#;
            
            fs::write(models_dir.join("test_model.rs"), model_content).unwrap();
            
            // Create test config that points to our temp directory
            let mut config = test_config();
            config.models.paths = vec![models_dir.to_str().unwrap().to_string()];
            config.migrations.dry_run = true; // Don't actually apply migrations
            
            #[cfg(feature = "tokio")]
            {
                let runtime = tokio::runtime::Runtime::new().unwrap();
                
                runtime.block_on(async {
                    // Create client
                    let mut client = SchemaSyncClient::new(config).await.unwrap();
                    
                    // Run sync workflow
                    let result = client.sync_database().await;
                    
                    // Should succeed with migrations (in dry run mode)
                    assert!(result.is_ok());
                });
            }
        }
    }
}
$$--GLUE--$$
.\schema_sync\src\utils\logging.rs
$$--GLUE--$$
//! Logging utilities for SchemaSync
//!
//! This module provides logging setup and configuration.

use tracing::{Level, metadata::LevelFilter};
use tracing_subscriber::{fmt, EnvFilter};
use std::path::Path;
use std::fs::File;

use crate::config::LoggingConfig;
use crate::error::Result;

/// Initialize logging based on configuration
pub fn init_logging(config: &Option<LoggingConfig>) -> Result<()> {
    let config = match config {
        Some(cfg) => cfg,
        None => return Ok(()), // No logging configuration, use defaults
    };
    
    // Parse log level
    let level = match config.level.to_lowercase().as_str() {
        "trace" => Level::TRACE,
        "debug" => Level::DEBUG,
        "info" => Level::INFO,
        "warn" => Level::WARN,
        "error" => Level::ERROR,
        _ => Level::INFO, // Default to INFO
    };
    
    // Create filter
    let filter = EnvFilter::from_default_env()
        .add_directive(format!("schema_sync={}", level).parse().unwrap());
    
    // Configure subscriber
    let subscriber = fmt::Subscriber::builder()
        .with_env_filter(filter)
        .with_ansi(true)
        .with_timer(fmt::time::time())
        .with_level(true);
    
    // Configure output
    if let Some(file_path) = &config.file {
        // Ensure directory exists
        if let Some(parent) = Path::new(file_path).parent() {
            std::fs::create_dir_all(parent)?;
        }
        
        // Open log file
        let file = File::create(file_path)?;
        
        // Set up logging to file
        let file_subscriber = match config.format.to_lowercase().as_str() {
            "json" => subscriber.json().with_writer(file),
            _ => subscriber.with_writer(file),
        };
        
        // Also log to stdout if configured
        if config.stdout {
            let stdout_subscriber = match config.format.to_lowercase().as_str() {
                "json" => subscriber.json().finish(),
                _ => subscriber.finish(),
            };
            
            // Set global subscriber
            tracing::subscriber::set_global_default(
                tracing_subscriber::registry()
                    .with(stdout_subscriber)
                    .with(file_subscriber)
            ).map_err(|e| crate::error::Error::Unknown(e.to_string()))?;
        } else {
            // Just file output
            tracing::subscriber::set_global_default(file_subscriber.finish())
                .map_err(|e| crate::error::Error::Unknown(e.to_string()))?;
        }
    } else if config.stdout {
        // Only stdout
        let stdout_subscriber = match config.format.to_lowercase().as_str() {
            "json" => subscriber.json().finish(),
            _ => subscriber.finish(),
        };
        
        tracing::subscriber::set_global_default(stdout_subscriber)
            .map_err(|e| crate::error::Error::Unknown(e.to_string()))?;
    }
    
    Ok(())
}

/// Log a message
#[macro_export]
macro_rules! log {
    ($level:expr, $($arg:tt)+) => {
        match $level {
            tracing::Level::ERROR => tracing::error!($($arg)+),
            tracing::Level::WARN => tracing::warn!($($arg)+),
            tracing::Level::INFO => tracing::info!($($arg)+),
            tracing::Level::DEBUG => tracing::debug!($($arg)+),
            tracing::Level::TRACE => tracing::trace!($($arg)+),
        }
    };
}
$$--GLUE--$$
.\schema_sync\src\utils\mod.rs
$$--GLUE--$$
//! Utilities for SchemaSync
//!
//! This module provides utility functions used across the library.

pub mod naming;
pub mod logging;

// Re-export key utility functions
pub use naming::{
    apply_naming_convention, format_name, get_table_name, 
    get_column_name, get_index_name, get_foreign_key_name,
};  
$$--GLUE--$$
.\schema_sync\src\utils\naming.rs
$$--GLUE--$$
//! Naming utilities for SchemaSync
//!
//! This module provides utilities for naming conventions and transformations.

use inflector::Inflector;

/// Apply a naming convention to a string
pub fn apply_naming_convention(name: &str, convention: &str) -> String {
    match convention {
        "snake_case" => name.to_snake_case(),
        "camel_case" => name.to_camel_case(),
        "pascal_case" => name.to_pascal_case(),
        "kebab_case" => name.to_kebab_case(),
        "screaming_snake_case" => name.to_screaming_snake_case(),
        _ => name.to_string(),
    }
}

/// Format a name according to a pattern
pub fn format_name(pattern: &str, replacements: &[(&str, &str)]) -> String {
    let mut result = pattern.to_string();
    
    for (placeholder, value) in replacements {
        result = result.replace(&format!("{{{}}}", placeholder), value);
    }
    
    result
}

/// Get table name from a model name
pub fn get_table_name(
    model_name: &str,
    style: &str,
    pluralize: bool,
) -> String {
    let name = apply_naming_convention(model_name, style);
    
    if pluralize {
        name.to_plural()
    } else {
        name
    }
}

/// Get column name from a field name
pub fn get_column_name(field_name: &str, style: &str) -> String {
    apply_naming_convention(field_name, style)
}

/// Get index name from table and columns
pub fn get_index_name(
    pattern: &str,
    table_name: &str,
    columns: &[String],
) -> String {
    let columns_str = columns.join("_");
    
    format_name(pattern, &[
        ("table", table_name),
        ("columns", &columns_str),
    ])
}

/// Get foreign key constraint name
pub fn get_foreign_key_name(
    pattern: &str,
    table_name: &str,
    column_name: &str,
) -> String {
    format_name(pattern, &[
        ("table", table_name),
        ("column", column_name),
    ])
}

/// Sanitize identifiers for SQL
pub fn sanitize_identifier(name: &str) -> String {
    // Remove or replace characters not allowed in SQL identifiers
    let mut sanitized = name.replace(|c: char| !c.is_alphanumeric() && c != '_', "_");
    
    // Ensure identifier doesn't start with a number
    if sanitized.chars().next().map_or(false, |c| c.is_numeric()) {
        sanitized = format!("_{}", sanitized);
    }
    
    sanitized
}

/// Check for name conflicts
pub fn check_identifier_conflicts(
    names: &[String],
    ignore_case: bool,
) -> Option<(String, String)> {
    let mut seen = std::collections::HashMap::new();
    
    for name in names {
        let key = if ignore_case { name.to_lowercase() } else { name.clone() };
        
        if let Some(existing) = seen.get(&key) {
            if name != existing {
                return Some((existing.clone(), name.clone()));
            }
        } else {
            seen.insert(key, name.clone());
        }
    }
    
    None
}

/// Truncate identifier to database limit
pub fn truncate_identifier(name: &str, max_length: usize) -> String {
    if name.len() <= max_length {
        name.to_string()
    } else {
        // Use first part and hash of full name to ensure uniqueness
        let hash = format!("{:x}", md5::compute(name.as_bytes()));
        let prefix_len = max_length - 9; // 8 chars for hash + 1 for underscore
        
        format!("{}_{}", &name[0..prefix_len], &hash[0..8])
    }
}
$$--GLUE--$$
.\schema_sync_macros\Cargo.lock
$$--GLUE--$$
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
version = 4

[[package]]
name = "once_cell"
version = "1.21.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d75b0bedcc4fe52caa0e03d9f1151a323e4aa5e2d78ba3580400cd3c9e2bc4bc"

[[package]]
name = "proc-macro2"
version = "1.0.94"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a31971752e70b8b2686d7e46ec17fb38dad4051d94024c88df49b667caea9c84"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "quote"
version = "1.0.40"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1885c039570dc00dcb4ff087a89e185fd56bae234ddc7f056a945bf36467248d"
dependencies = [
 "proc-macro2",
]

[[package]]
name = "schema_sync_macros"
version = "0.1.0"
dependencies = [
 "once_cell",
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "syn"
version = "2.0.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b09a44accad81e1ba1cd74a32461ba89dee89095ba17b32f5d03683b1b1fc2a0"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "unicode-ident"
version = "1.0.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5a5f39404a5da50712a4c1eecf25e90dd62b613502b7e925fd4e4d19b5c96512"

$$--GLUE--$$
.\schema_sync_macros\cargo.toml
$$--GLUE--$$
[package]
name = "schema_sync_macros"
version = "0.1.0"
edition = "2021"
authors = ["Your Name <your.email@example.com>"]
description = "Procedural macros for SchemaSync"
license = "MIT OR Apache-2.0"
repository = "https://github.com/yourusername/schema_sync"
keywords = ["database", "orm", "schema", "migrations", "macros"]
categories = ["database"]

[lib]
proc-macro = true

[dependencies]
proc-macro2 = "1.0"
quote = "1.0"
syn = { version = "2.0", features = ["full", "extra-traits"] }
once_cell = "1.19"
$$--GLUE--$$
.\schema_sync_macros\src\lib.rs
$$--GLUE--$$
//! Procedural macros for SchemaSync
//!
//! This crate provides the #[schema_sync] attribute macro and SchemaSync derive macro
//! for model registration with the schema_sync library.

use once_cell::sync::Lazy;
use proc_macro::TokenStream;
use proc_macro2::TokenStream as TokenStream2;
use quote::{quote, ToTokens};
use syn::{parse_macro_input, Data, DeriveInput, Fields};
use std::sync::Mutex;

/// Registry for models that are decorated with the #[schema_sync] attribute
static MODEL_REGISTRY: Lazy<Mutex<Vec<String>>> = Lazy::new(|| Mutex::new(Vec::new()));

/// Attribute macro for marking structs to be included in schema generation
#[proc_macro_attribute]
pub fn schema_sync(attr: TokenStream, item: TokenStream) -> TokenStream {
    // Parse the input tokens into a syntax tree
    let input = parse_macro_input!(item as DeriveInput);
    let name = input.ident.to_string();
    
    // Register this model
    MODEL_REGISTRY.lock().unwrap().push(name.clone());
    
    // Parse attribute arguments
    let attr_args = parse_attribute_args(proc_macro2::TokenStream::from(attr));
    
    // Generate the modified struct with additional attributes
    let expanded = expand_struct(input, attr_args);
    
    proc_macro::TokenStream::from(expanded)
}

/// Parse attribute arguments like table name, indexes, etc.
fn parse_attribute_args(attr: TokenStream2) -> Vec<(String, String)> {
    // For the basic implementation, just returning empty vec
    // In a real implementation, this would parse arguments like:
    // #[schema_sync(table = "users", index = ["email", "username"])]
    Vec::new()
}

/// Expand the struct definition with required traits and methods
fn expand_struct(input: DeriveInput, attr_args: Vec<(String, String)>) -> TokenStream2 {
    let name = &input.ident;
    let generics = &input.generics;
    let (impl_generics, ty_generics, where_clause) = generics.split_for_impl();
    
    // Extract field information for schema generation
    let fields = match &input.data {
        Data::Struct(data) => match &data.fields {
            Fields::Named(fields) => &fields.named,
            _ => panic!("SchemaSync only supports structs with named fields"),
        },
        _ => panic!("SchemaSync only supports structs"),
    };
    
    // Generate implementation of SchemaSync trait
    let expanded = quote! {
        // Original struct
        #input
        
        #[automatically_derived]
        impl #impl_generics schema_sync::models::SchemaSyncModel for #name #ty_generics #where_clause {
            fn get_table_name() -> String {
                // In a real implementation, this would use the table name from attribute args
                // or apply naming conventions from config
                stringify!(#name).to_string()
            }
            
            fn get_field_definitions() -> Vec<schema_sync::schema::types::FieldDefinition> {
                // In a real implementation, this would extract field types and attributes
                vec![]
            }
            
            fn register_with_schema_sync() {
                // Registration logic
            }
        }
    };
    
    expanded
}

/// Derive macro for SchemaSync
#[proc_macro_derive(SchemaSync, attributes(schema_sync_field))]
pub fn derive_schema_sync(input: TokenStream) -> TokenStream {
    let input = parse_macro_input!(input as DeriveInput);
    let name = &input.ident;
    let expanded = quote! {
        impl schema_sync::models::SchemaSyncModel for #name {
            // Implementation details
            fn get_table_name() -> String {
                stringify!(#name).to_string()
            }
            
            fn get_field_definitions() -> Vec<schema_sync::schema::types::FieldDefinition> {
                vec![]
            }
            
            fn register_with_schema_sync() {
                // Registration logic
            }
        }
    };
    
    TokenStream::from(expanded)
}
$$--GLUE--$$
.\schema_sync_macros\target\.rustc_info.json
$$--GLUE--$$
{"rustc_fingerprint":14442349487907958269,"outputs":{"13331785392996375709":{"success":true,"status":"","code":0,"stdout":"___.exe\nlib___.rlib\n___.dll\n___.dll\n___.lib\n___.dll\nC:\\Users\\trident\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\npacked\n___\ndebug_assertions\npanic=\"unwind\"\nproc_macro\ntarget_abi=\"\"\ntarget_arch=\"x86_64\"\ntarget_endian=\"little\"\ntarget_env=\"msvc\"\ntarget_family=\"windows\"\ntarget_feature=\"cmpxchg16b\"\ntarget_feature=\"fxsr\"\ntarget_feature=\"sse\"\ntarget_feature=\"sse2\"\ntarget_feature=\"sse3\"\ntarget_has_atomic=\"128\"\ntarget_has_atomic=\"16\"\ntarget_has_atomic=\"32\"\ntarget_has_atomic=\"64\"\ntarget_has_atomic=\"8\"\ntarget_has_atomic=\"ptr\"\ntarget_os=\"windows\"\ntarget_pointer_width=\"64\"\ntarget_vendor=\"pc\"\nwindows\n","stderr":""},"17747080675513052775":{"success":true,"status":"","code":0,"stdout":"rustc 1.85.0 (4d91de4e4 2025-02-17)\nbinary: rustc\ncommit-hash: 4d91de4e48198da2e33413efdcd9cd2cc0c46688\ncommit-date: 2025-02-17\nhost: x86_64-pc-windows-msvc\nrelease: 1.85.0\nLLVM version: 19.1.7\n","stderr":""},"17313545009459141857":{"success":true,"status":"","code":0,"stdout":"___.exe\nlib___.rlib\n___.dll\n___.dll\n___.lib\n___.dll\nC:\\Users\\trident\\.rustup\\toolchains\\stable-x86_64-pc-windows-msvc\npacked\n___\ndebug_assertions\npanic=\"unwind\"\nproc_macro\ntarget_abi=\"\"\ntarget_arch=\"x86_64\"\ntarget_endian=\"little\"\ntarget_env=\"msvc\"\ntarget_family=\"windows\"\ntarget_feature=\"cmpxchg16b\"\ntarget_feature=\"fxsr\"\ntarget_feature=\"sse\"\ntarget_feature=\"sse2\"\ntarget_feature=\"sse3\"\ntarget_has_atomic=\"128\"\ntarget_has_atomic=\"16\"\ntarget_has_atomic=\"32\"\ntarget_has_atomic=\"64\"\ntarget_has_atomic=\"8\"\ntarget_has_atomic=\"ptr\"\ntarget_os=\"windows\"\ntarget_pointer_width=\"64\"\ntarget_vendor=\"pc\"\nwindows\n","stderr":""}},"successes":{}}
$$--GLUE--$$
.\schema_sync_macros\target\CACHEDIR.TAG
$$--GLUE--$$
Signature: 8a477f597d28d172789f06886806bc55
# This file is a cache directory tag created by cargo.
# For information about cache directory tags see https://bford.info/cachedir/

$$--GLUE--$$
.\schema_sync_macros\target\debug\.cargo-lock
$$--GLUE--$$

$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\once_cell-e20d82cdf859cd7b\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\once_cell-e20d82cdf859cd7b\lib-once_cell
$$--GLUE--$$
1841a237f8dd50fe
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\once_cell-e20d82cdf859cd7b\lib-once_cell.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[\"alloc\", \"default\", \"race\", \"std\"]","declared_features":"[\"alloc\", \"atomic-polyfill\", \"critical-section\", \"default\", \"parking_lot\", \"portable-atomic\", \"race\", \"std\", \"unstable\"]","target":17524666916136250164,"profile":12410652206962508598,"path":16785146413638129144,"deps":[],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\once_cell-e20d82cdf859cd7b\\dep-lib-once_cell","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-040bb96dd1c89721\run-build-script-build-script-build
$$--GLUE--$$
ef645c1d1f938ad6
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-040bb96dd1c89721\run-build-script-build-script-build.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"","declared_features":"","target":0,"profile":0,"path":0,"deps":[[12410540580958238005,"build_script_build",false,9182132484191922543]],"local":[{"RerunIfChanged":{"output":"debug\\build\\proc-macro2-040bb96dd1c89721\\output","paths":["build/probe.rs"]}},{"RerunIfEnvChanged":{"var":"RUSTC_BOOTSTRAP","val":null}}],"rustflags":[],"config":0,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-b63e35dd58db7206\build-script-build-script-build
$$--GLUE--$$
6fa9d568d87c6d7f
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-b63e35dd58db7206\build-script-build-script-build.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[\"default\", \"proc-macro\"]","declared_features":"[\"default\", \"nightly\", \"proc-macro\", \"span-locations\"]","target":5408242616063297496,"profile":2225463790103693989,"path":9557236546914816211,"deps":[],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\proc-macro2-b63e35dd58db7206\\dep-build-script-build-script-build","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-b63e35dd58db7206\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-d47818efde72ec6c\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-d47818efde72ec6c\lib-proc_macro2
$$--GLUE--$$
9678583a27a8fae8
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\proc-macro2-d47818efde72ec6c\lib-proc_macro2.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[\"default\", \"proc-macro\"]","declared_features":"[\"default\", \"nightly\", \"proc-macro\", \"span-locations\"]","target":369203346396300798,"profile":12410652206962508598,"path":17441433330969666635,"deps":[[1988483478007900009,"unicode_ident",false,840513119146141001],[12410540580958238005,"build_script_build",false,15459330432748512495]],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\proc-macro2-d47818efde72ec6c\\dep-lib-proc_macro2","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\quote-01bd2894e6929790\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\quote-01bd2894e6929790\lib-quote
$$--GLUE--$$
ad6a3e369d254d00
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\quote-01bd2894e6929790\lib-quote.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[\"default\", \"proc-macro\"]","declared_features":"[\"default\", \"proc-macro\"]","target":3570458776599611685,"profile":12410652206962508598,"path":9381626496108189652,"deps":[[12410540580958238005,"proc_macro2",false,16787915447413012630]],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\quote-01bd2894e6929790\\dep-lib-quote","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1c9f1002e2e24dfb\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1c9f1002e2e24dfb\output-test-lib-schema_sync_macros
$$--GLUE--$$
{"$message_type":"diagnostic","message":"unused import: `ToTokens`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":315,"byte_end":323,"line_start":9,"line_end":9,"column_start":20,"column_end":28,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":20,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_imports)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":313,"byte_end":323,"line_start":9,"line_end":9,"column_start":18,"column_end":28,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":18,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src\\lib.rs","byte_start":307,"byte_end":308,"line_start":9,"line_end":9,"column_start":12,"column_end":13,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":12,"highlight_end":13}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src\\lib.rs","byte_start":323,"byte_end":324,"line_start":9,"line_end":9,"column_start":28,"column_end":29,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":28,"highlight_end":29}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused import: `ToTokens`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:9:20\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m9\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse quote::{quote, ToTokens};\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^^^^^\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m= \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15mnote\u001b[0m\u001b[0m: `#[warn(unused_imports)]` on by default\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `attr`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":1381,"byte_end":1385,"line_start":36,"line_end":36,"column_start":25,"column_end":29,"is_primary":true,"text":[{"text":"fn parse_attribute_args(attr: TokenStream2) -> Vec<(String, String)> {","highlight_start":25,"highlight_end":29}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_variables)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":1381,"byte_end":1385,"line_start":36,"line_end":36,"column_start":25,"column_end":29,"is_primary":true,"text":[{"text":"fn parse_attribute_args(attr: TokenStream2) -> Vec<(String, String)> {","highlight_start":25,"highlight_end":29}],"label":null,"suggested_replacement":"_attr","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused variable: `attr`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:36:25\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m36\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mfn parse_attribute_args(attr: TokenStream2) -> Vec<(String, String)> {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11mhelp: if this is intentional, prefix it with an underscore: `_attr`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m= \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15mnote\u001b[0m\u001b[0m: `#[warn(unused_variables)]` on by default\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `fields`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":2026,"byte_end":2032,"line_start":50,"line_end":50,"column_start":9,"column_end":15,"is_primary":true,"text":[{"text":"    let fields = match &input.data {","highlight_start":9,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":2026,"byte_end":2032,"line_start":50,"line_end":50,"column_start":9,"column_end":15,"is_primary":true,"text":[{"text":"    let fields = match &input.data {","highlight_start":9,"highlight_end":15}],"label":null,"suggested_replacement":"_fields","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused variable: `fields`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:50:9\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m50\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let fields = match &input.data {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11mhelp: if this is intentional, prefix it with an underscore: `_fields`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `attr_args`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":1755,"byte_end":1764,"line_start":44,"line_end":44,"column_start":38,"column_end":47,"is_primary":true,"text":[{"text":"fn expand_struct(input: DeriveInput, attr_args: Vec<(String, String)>) -> TokenStream2 {","highlight_start":38,"highlight_end":47}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":1755,"byte_end":1764,"line_start":44,"line_end":44,"column_start":38,"column_end":47,"is_primary":true,"text":[{"text":"fn expand_struct(input: DeriveInput, attr_args: Vec<(String, String)>) -> TokenStream2 {","highlight_start":38,"highlight_end":47}],"label":null,"suggested_replacement":"_attr_args","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused variable: `attr_args`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:44:38\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m44\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mfn expand_struct(input: DeriveInput, attr_args: Vec<(String, String)>) -> TokenStream2 {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m                                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11mhelp: if this is intentional, prefix it with an underscore: `_attr_args`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"4 warnings emitted","code":null,"level":"warning","spans":[],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: 4 warnings emitted\u001b[0m\n\n"}

$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1c9f1002e2e24dfb\test-lib-schema_sync_macros
$$--GLUE--$$
a347dd32f92d195e
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1c9f1002e2e24dfb\test-lib-schema_sync_macros.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[]","declared_features":"[]","target":12516767817851295881,"profile":3316208278650011218,"path":10763286916239946207,"deps":[[1213962973451362254,"once_cell",false,18325390941925556504],[8986759836770526006,"syn",false,8606269454081308846],[12410540580958238005,"proc_macro2",false,16787915447413012630],[17990358020177143287,"quote",false,21714930356873901]],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\schema_sync_macros-1c9f1002e2e24dfb\\dep-test-lib-schema_sync_macros","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1f62c371879a9f30\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1f62c371879a9f30\lib-schema_sync_macros
$$--GLUE--$$
ef035e9a0df63ab4
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1f62c371879a9f30\lib-schema_sync_macros.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[]","declared_features":"[]","target":12516767817851295881,"profile":17672942494452627365,"path":10763286916239946207,"deps":[[1213962973451362254,"once_cell",false,18325390941925556504],[8986759836770526006,"syn",false,8606269454081308846],[12410540580958238005,"proc_macro2",false,16787915447413012630],[17990358020177143287,"quote",false,21714930356873901]],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\schema_sync_macros-1f62c371879a9f30\\dep-lib-schema_sync_macros","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\schema_sync_macros-1f62c371879a9f30\output-lib-schema_sync_macros
$$--GLUE--$$
{"$message_type":"diagnostic","message":"unused import: `ToTokens`","code":{"code":"unused_imports","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":315,"byte_end":323,"line_start":9,"line_end":9,"column_start":20,"column_end":28,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":20,"highlight_end":28}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_imports)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"remove the unused import","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":313,"byte_end":323,"line_start":9,"line_end":9,"column_start":18,"column_end":28,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":18,"highlight_end":28}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src\\lib.rs","byte_start":307,"byte_end":308,"line_start":9,"line_end":9,"column_start":12,"column_end":13,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":12,"highlight_end":13}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null},{"file_name":"src\\lib.rs","byte_start":323,"byte_end":324,"line_start":9,"line_end":9,"column_start":28,"column_end":29,"is_primary":true,"text":[{"text":"use quote::{quote, ToTokens};","highlight_start":28,"highlight_end":29}],"label":null,"suggested_replacement":"","suggestion_applicability":"MachineApplicable","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused import: `ToTokens`\u001b[0m\n\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:9:20\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m9\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0muse quote::{quote, ToTokens};\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m                    \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^^^^^\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m= \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15mnote\u001b[0m\u001b[0m: `#[warn(unused_imports)]` on by default\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `attr`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":1381,"byte_end":1385,"line_start":36,"line_end":36,"column_start":25,"column_end":29,"is_primary":true,"text":[{"text":"fn parse_attribute_args(attr: TokenStream2) -> Vec<(String, String)> {","highlight_start":25,"highlight_end":29}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"`#[warn(unused_variables)]` on by default","code":null,"level":"note","spans":[],"children":[],"rendered":null},{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":1381,"byte_end":1385,"line_start":36,"line_end":36,"column_start":25,"column_end":29,"is_primary":true,"text":[{"text":"fn parse_attribute_args(attr: TokenStream2) -> Vec<(String, String)> {","highlight_start":25,"highlight_end":29}],"label":null,"suggested_replacement":"_attr","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused variable: `attr`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:36:25\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m36\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mfn parse_attribute_args(attr: TokenStream2) -> Vec<(String, String)> {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m                         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11mhelp: if this is intentional, prefix it with an underscore: `_attr`\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m= \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15mnote\u001b[0m\u001b[0m: `#[warn(unused_variables)]` on by default\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `fields`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":2026,"byte_end":2032,"line_start":50,"line_end":50,"column_start":9,"column_end":15,"is_primary":true,"text":[{"text":"    let fields = match &input.data {","highlight_start":9,"highlight_end":15}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":2026,"byte_end":2032,"line_start":50,"line_end":50,"column_start":9,"column_end":15,"is_primary":true,"text":[{"text":"    let fields = match &input.data {","highlight_start":9,"highlight_end":15}],"label":null,"suggested_replacement":"_fields","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused variable: `fields`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:50:9\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m50\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0m    let fields = match &input.data {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m         \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11mhelp: if this is intentional, prefix it with an underscore: `_fields`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"unused variable: `attr_args`","code":{"code":"unused_variables","explanation":null},"level":"warning","spans":[{"file_name":"src\\lib.rs","byte_start":1755,"byte_end":1764,"line_start":44,"line_end":44,"column_start":38,"column_end":47,"is_primary":true,"text":[{"text":"fn expand_struct(input: DeriveInput, attr_args: Vec<(String, String)>) -> TokenStream2 {","highlight_start":38,"highlight_end":47}],"label":null,"suggested_replacement":null,"suggestion_applicability":null,"expansion":null}],"children":[{"message":"if this is intentional, prefix it with an underscore","code":null,"level":"help","spans":[{"file_name":"src\\lib.rs","byte_start":1755,"byte_end":1764,"line_start":44,"line_end":44,"column_start":38,"column_end":47,"is_primary":true,"text":[{"text":"fn expand_struct(input: DeriveInput, attr_args: Vec<(String, String)>) -> TokenStream2 {","highlight_start":38,"highlight_end":47}],"label":null,"suggested_replacement":"_attr_args","suggestion_applicability":"MaybeIncorrect","expansion":null}],"children":[],"rendered":null}],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: unused variable: `attr_args`\u001b[0m\n\u001b[0m  \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m--> \u001b[0m\u001b[0msrc\\lib.rs:44:38\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\n\u001b[0m\u001b[1m\u001b[38;5;14m44\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m \u001b[0m\u001b[0mfn expand_struct(input: DeriveInput, attr_args: Vec<(String, String)>) -> TokenStream2 {\u001b[0m\n\u001b[0m   \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;14m|\u001b[0m\u001b[0m                                      \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11m^^^^^^^^^\u001b[0m\u001b[0m \u001b[0m\u001b[0m\u001b[1m\u001b[38;5;11mhelp: if this is intentional, prefix it with an underscore: `_attr_args`\u001b[0m\n\n"}
{"$message_type":"diagnostic","message":"4 warnings emitted","code":null,"level":"warning","spans":[],"children":[],"rendered":"\u001b[0m\u001b[1m\u001b[38;5;11mwarning\u001b[0m\u001b[0m\u001b[1m\u001b[38;5;15m: 4 warnings emitted\u001b[0m\n\n"}

$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\syn-cc4e962a231eb42f\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\syn-cc4e962a231eb42f\lib-syn
$$--GLUE--$$
aeb8cf73789c6f77
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\syn-cc4e962a231eb42f\lib-syn.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[\"clone-impls\", \"default\", \"derive\", \"extra-traits\", \"full\", \"parsing\", \"printing\", \"proc-macro\"]","declared_features":"[\"clone-impls\", \"default\", \"derive\", \"extra-traits\", \"fold\", \"full\", \"parsing\", \"printing\", \"proc-macro\", \"test\", \"visit\", \"visit-mut\"]","target":9442126953582868550,"profile":12410652206962508598,"path":453491548146934202,"deps":[[1988483478007900009,"unicode_ident",false,840513119146141001],[12410540580958238005,"proc_macro2",false,16787915447413012630],[17990358020177143287,"quote",false,21714930356873901]],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\syn-cc4e962a231eb42f\\dep-lib-syn","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\unicode-ident-7e56172d8d7328a7\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\unicode-ident-7e56172d8d7328a7\lib-unicode_ident
$$--GLUE--$$
49e5c2873a1aaa0b
$$--GLUE--$$
.\schema_sync_macros\target\debug\.fingerprint\unicode-ident-7e56172d8d7328a7\lib-unicode_ident.json
$$--GLUE--$$
{"rustc":13800692020808712694,"features":"[]","declared_features":"[]","target":5438535436255082082,"profile":12410652206962508598,"path":9354677547362738889,"deps":[],"local":[{"CheckDepInfo":{"dep_info":"debug\\.fingerprint\\unicode-ident-7e56172d8d7328a7\\dep-lib-unicode_ident","checksum":false}}],"rustflags":[],"config":2069994364910194474,"compile_kind":0}
$$--GLUE--$$
.\schema_sync_macros\target\debug\build\proc-macro2-040bb96dd1c89721\invoked.timestamp
$$--GLUE--$$
This file has an mtime of when this was started.
$$--GLUE--$$
.\schema_sync_macros\target\debug\build\proc-macro2-040bb96dd1c89721\output
$$--GLUE--$$
cargo:rustc-check-cfg=cfg(fuzzing)
cargo:rustc-check-cfg=cfg(no_is_available)
cargo:rustc-check-cfg=cfg(no_literal_byte_character)
cargo:rustc-check-cfg=cfg(no_literal_c_string)
cargo:rustc-check-cfg=cfg(no_source_text)
cargo:rustc-check-cfg=cfg(proc_macro_span)
cargo:rustc-check-cfg=cfg(procmacro2_backtrace)
cargo:rustc-check-cfg=cfg(procmacro2_nightly_testing)
cargo:rustc-check-cfg=cfg(procmacro2_semver_exempt)
cargo:rustc-check-cfg=cfg(randomize_layout)
cargo:rustc-check-cfg=cfg(span_locations)
cargo:rustc-check-cfg=cfg(super_unstable)
cargo:rustc-check-cfg=cfg(wrap_proc_macro)
cargo:rerun-if-changed=build/probe.rs
cargo:rustc-cfg=wrap_proc_macro
cargo:rerun-if-env-changed=RUSTC_BOOTSTRAP

$$--GLUE--$$
.\schema_sync_macros\target\debug\build\proc-macro2-040bb96dd1c89721\root-output
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\build\proc-macro2-040bb96dd1c89721\out
$$--GLUE--$$
.\schema_sync_macros\target\debug\build\proc-macro2-040bb96dd1c89721\stderr
$$--GLUE--$$

$$--GLUE--$$
.\schema_sync_macros\target\debug\build\proc-macro2-b63e35dd58db7206\build_script_build-b63e35dd58db7206.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\build\proc-macro2-b63e35dd58db7206\build_script_build-b63e35dd58db7206.exe: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\build.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\build\proc-macro2-b63e35dd58db7206\build_script_build-b63e35dd58db7206.d: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\build.rs

C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\build.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\libschema_sync_macros-1c9f1002e2e24dfb.rmeta
$$--GLUE--$$

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\once_cell-e20d82cdf859cd7b.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\libonce_cell-e20d82cdf859cd7b.rmeta: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\imp_std.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\race.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\once_cell-e20d82cdf859cd7b.d: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\imp_std.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\race.rs

C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\lib.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\imp_std.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\once_cell-1.21.1\src\race.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\proc_macro2-d47818efde72ec6c.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\libproc_macro2-d47818efde72ec6c.rmeta: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\marker.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\parse.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\rcvec.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\detection.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\fallback.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\extra.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\wrapper.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\proc_macro2-d47818efde72ec6c.d: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\marker.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\parse.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\rcvec.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\detection.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\fallback.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\extra.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\wrapper.rs

C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\lib.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\marker.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\parse.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\rcvec.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\detection.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\fallback.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\extra.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\proc-macro2-1.0.94\src\wrapper.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\quote-01bd2894e6929790.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\libquote-01bd2894e6929790.rmeta: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\ext.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\format.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\ident_fragment.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\to_tokens.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\runtime.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\spanned.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\quote-01bd2894e6929790.d: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\ext.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\format.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\ident_fragment.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\to_tokens.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\runtime.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\spanned.rs

C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\lib.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\ext.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\format.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\ident_fragment.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\to_tokens.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\runtime.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\quote-1.0.40\src\spanned.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\schema_sync_macros-1c9f1002e2e24dfb.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\libschema_sync_macros-1c9f1002e2e24dfb.rmeta: src\lib.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\schema_sync_macros-1c9f1002e2e24dfb.d: src\lib.rs

src\lib.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\schema_sync_macros-1f62c371879a9f30.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\libschema_sync_macros-1f62c371879a9f30.rmeta: src\lib.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\schema_sync_macros-1f62c371879a9f30.d: src\lib.rs

src\lib.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\syn-cc4e962a231eb42f.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\libsyn-cc4e962a231eb42f.rmeta: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\macros.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\group.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\token.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\attr.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\bigint.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\buffer.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\classify.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\custom_keyword.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\custom_punctuation.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\data.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\derive.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\drops.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\error.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\expr.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ext.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\file.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\fixup.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\generics.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ident.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\item.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lifetime.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lit.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lookahead.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\mac.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\meta.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\op.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\discouraged.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse_macro_input.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse_quote.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\pat.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\path.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\precedence.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\print.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\punctuated.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\restriction.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\sealed.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\span.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\spanned.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\stmt.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\thread.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\tt.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ty.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\verbatim.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\whitespace.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\export.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\clone.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\debug.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\eq.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\hash.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\syn-cc4e962a231eb42f.d: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\macros.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\group.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\token.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\attr.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\bigint.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\buffer.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\classify.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\custom_keyword.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\custom_punctuation.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\data.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\derive.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\drops.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\error.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\expr.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ext.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\file.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\fixup.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\generics.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ident.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\item.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lifetime.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lit.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lookahead.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\mac.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\meta.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\op.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\discouraged.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse_macro_input.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse_quote.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\pat.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\path.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\precedence.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\print.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\punctuated.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\restriction.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\sealed.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\span.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\spanned.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\stmt.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\thread.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\tt.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ty.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\verbatim.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\whitespace.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\export.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\clone.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\debug.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\eq.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\hash.rs

C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lib.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\macros.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\group.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\token.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\attr.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\bigint.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\buffer.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\classify.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\custom_keyword.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\custom_punctuation.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\data.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\derive.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\drops.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\error.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\expr.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ext.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\file.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\fixup.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\generics.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ident.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\item.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lifetime.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lit.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\lookahead.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\mac.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\meta.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\op.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\discouraged.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse_macro_input.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\parse_quote.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\pat.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\path.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\precedence.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\print.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\punctuated.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\restriction.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\sealed.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\span.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\spanned.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\stmt.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\thread.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\tt.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\ty.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\verbatim.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\whitespace.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\export.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\clone.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\debug.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\eq.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\syn-2.0.100\src\gen\hash.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\deps\unicode_ident-7e56172d8d7328a7.d
$$--GLUE--$$
C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\libunicode_ident-7e56172d8d7328a7.rmeta: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\unicode-ident-1.0.18\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\unicode-ident-1.0.18\src\tables.rs

C:\Users\trident\Documents\GitHub\SchemaSync\schema_sync_macros\target\debug\deps\unicode_ident-7e56172d8d7328a7.d: C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\unicode-ident-1.0.18\src\lib.rs C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\unicode-ident-1.0.18\src\tables.rs

C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\unicode-ident-1.0.18\src\lib.rs:
C:\Users\trident\.cargo\registry\src\index.crates.io-1949cf8c6b5b557f\unicode-ident-1.0.18\src\tables.rs:

$$--GLUE--$$
.\schema_sync_macros\target\debug\incremental\schema_sync_macros-0ukwwxupub7y3\s-h5r1yns9yr-0y3nve8.lock
$$--GLUE--$$

$$--GLUE--$$
.\schema_sync_macros\target\debug\incremental\schema_sync_macros-3hie2j6sr7sa4\s-h5r1ynsc85-120yfi2.lock
$$--GLUE--$$
